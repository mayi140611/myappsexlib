{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp traindl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户的点击当做一个序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lib导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import custom_attn\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "# import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from mylib.utils.pickle import PickleWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import gc\n",
    "import tqdm\n",
    "import os\n",
    "from tx.config import * \n",
    "from tx.eda import * \n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)  # 设置显示数据的最大列数，防止出现省略号…，导致数据显示不全\n",
    "pd.set_option('expand_frame_repr', False)  # 当列太多时不自动换行\n",
    "# from multiprocessing.dummy import Pool\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = logger.add(os.path.join(args.DATA_DIR, 'data_gen/runtime.log'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_FILE = os.path.join(args.DATA_DIR, 'data_gen/word2vector.model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covers about 95% of input data\n",
    "MAX_SENTS = 91 # maximum number of sentences per document\n",
    "MAX_WORDS = 26 # maximum number of words per sentence\n",
    "\n",
    "WORD_EMBED_SIZE = 128\n",
    "SENT_EMBED_SIZE = 100\n",
    "DOC_EMBED_SIZE = 50\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_from_text = KeyedVectors.load_word2vec_format(VOCAB_FILE, binary=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 3412774\n"
     ]
    }
   ],
   "source": [
    "words = ['PAD'] + wv_from_text.index2word\n",
    "\n",
    "word2id = dict(zip(words, range(len(words))))\n",
    "\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "vocab_size = len(word2id)\n",
    "print(\"vocab_size: {:d}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PickleWrapper.dump2File(word2id, os.path.join(args.DATA_DIR, 'data_gen/creativeid2id_dict.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load w2v Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3412774, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.zeros((vocab_size, WORD_EMBED_SIZE))\n",
    "\n",
    "E[1:] = wv_from_text.vectors\n",
    "\n",
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.1.0\n",
    "# -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['like', 'a', 'mouse']\n",
      "[0, 'The', 'cat', 'fought', 'like', 'a', 'mouse']\n"
     ]
    }
   ],
   "source": [
    "def pad_or_truncate(xs, maxlen):\n",
    "    if len(xs) > maxlen:\n",
    "        return xs[len(xs) - maxlen:]\n",
    "#     return [\"PAD\"] * (maxlen - len(xs)) + xs\n",
    "    return [0] * (maxlen - len(xs)) + xs\n",
    "\n",
    "xs = [\"The\", \"cat\", \"fought\", \"like\", \"a\", \"mouse\"]\n",
    "print(pad_or_truncate(xs, 3))\n",
    "print(pad_or_truncate(xs, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rtest = PickleWrapper.loadFromFile(os.path.join(args.DATA_DIR, 'data_gen/test_creative_id.pkl'))\n",
    "\n",
    "rtrain = PickleWrapper.loadFromFile(os.path.join(args.DATA_DIR, 'data_gen/train1_creative_id.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = 'user_id age gender'.split()\n",
    "user_train = pd.read_csv(os.path.join(args.DATA_DIR, 'data_origin/train_preliminary/user.csv'), converters={c: str for c in str_cols}).set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender2id = user_train.gender.map(lambda s: int(s)-1)\n",
    "age2id = user_train.age.map(lambda s: int(s)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age gender\n",
       "user_id           \n",
       "1         4      1\n",
       "2        10      1\n",
       "3         7      2\n",
       "4         5      1\n",
       "5         4      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1     [[[1], [1], [1], [1], [1], [1], [1], [1], [1],...\n",
       "10    [[[1], [1], [1], [119124, 1], [1], [1], [18, 1...\n",
       "dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtrain[0].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch_generator(batch_size=1000):\n",
    "    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "    y_gender = []\n",
    "    y_age = []\n",
    "    cnt = 0\n",
    "    ii = 0\n",
    "    while True:\n",
    "        \n",
    "        # print(f'\\ntrain{ii}')\n",
    "        r = PickleWrapper.loadFromFile(f'/content/train_file/train1_creative_id{ii}.pkl')\n",
    "        if ii == 43:\n",
    "            ii = 0\n",
    "        else:\n",
    "            ii += 1\n",
    "        for uu in [r]:\n",
    "            for i, v in uu.items():\n",
    "        #             print(v[0])\n",
    "        #             print('--------')\n",
    "                # y_gender.append(gender2id[i])\n",
    "                y_age.append(age2id[i])\n",
    "                #Shuffle list x in place, and return None.\n",
    "                \n",
    "                sents = v[0]\n",
    "        #             print(sents)\n",
    "\n",
    "        #             in_queue, out_queue = Manager().Queue(), Manager().Queue()\n",
    "\n",
    "        #             for sid, words in enumerate(sents):\n",
    "        #                 in_queue.put((sid, words))\n",
    "        #             def f(in_queue, out_queue):\n",
    "\n",
    "        #                 while not in_queue.empty():\n",
    "        # #                     print(f'in_queue.qsize: {in_queue.qsize()}')\n",
    "        #                     sid, words = in_queue.get()\n",
    "        # #                     print(sid)\n",
    "                for sid, words in enumerate(sents):\n",
    "                    t_ = words[:-1]\n",
    "                    if len(t_) > 1:\n",
    "                      random.shuffle(t_)\n",
    "                    words = pad_or_truncate(t_+[1], MAX_WORDS)\n",
    "        #                 print(sid)\n",
    "        #                 print(words)\n",
    "        #                     wordsid = pd.Series(words).map(word2id).tolist()\n",
    "        #                     out_queue.put((sid, words))\n",
    "        #             pool = Pool(30, f, (in_queue, out_queue))\n",
    "        #             pool.close()\n",
    "        #             pool.join()\n",
    "        #             while not out_queue.empty():\n",
    "        # #                 print(f'out_queue.qsize: {out_queue.qsize()}')\n",
    "        #                 sid, wordsid = out_queue.get()\n",
    "        #                 print(wordsid)\n",
    "                    X[cnt, sid] = words\n",
    "                cnt += 1\n",
    "                if cnt == batch_size:\n",
    "                    yield X, to_categorical(y_age, num_classes=NUM_CLASSES)# y_gender, y_age\n",
    "                    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "                    y_gender = []\n",
    "                    y_age = []\n",
    "                    cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch_generator(batch_size=20000):\n",
    "    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "    y_gender = []\n",
    "    y_age = []\n",
    "    cnt = 0\n",
    "    r = PickleWrapper.loadFromFile(f'/content/train_file/train1_creative_id44.pkl')\n",
    "    while True:\n",
    "        for uu in [r]:\n",
    "            for i, v in uu.items():\n",
    "                # y_gender.append(gender2id[i])\n",
    "                y_age.append(age2id[i])\n",
    "                sents = v[0]\n",
    "                for sid, words in enumerate(sents):\n",
    "                    t_ = words[:-1]\n",
    "                    if len(t_) > 1:\n",
    "                      random.shuffle(t_)\n",
    "                    words = pad_or_truncate(t_+[1], MAX_WORDS)\n",
    "                    X[cnt, sid] = words\n",
    "                cnt += 1\n",
    "                if cnt == batch_size:\n",
    "                    yield X, to_categorical(y_age, num_classes=NUM_CLASSES)# y_gender, y_age\n",
    "                    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "                    y_gender = []\n",
    "                    y_age = []\n",
    "                    cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch_generator(batch_size=20000):\n",
    "    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "    y_gender = []\n",
    "    y_age = []\n",
    "    cnt = 0\n",
    "    r = PickleWrapper.loadFromFile(f'/content/train_file/train1_creative_id44.pkl')\n",
    "    while True:\n",
    "        for uu in [r]:\n",
    "            for i, v in uu.items():\n",
    "                # y_gender.append(gender2id[i])\n",
    "                y_age.append(age2id[i])\n",
    "                sents = v[0]\n",
    "                for sid, words in enumerate(sents):\n",
    "                    t_ = words[:-1]\n",
    "                    if len(t_) > 1:\n",
    "                      random.shuffle(t_)\n",
    "                    words = pad_or_truncate(t_+[1], MAX_WORDS)\n",
    "                    X[cnt, sid] = words\n",
    "                cnt += 1\n",
    "                if cnt == batch_size:\n",
    "                    yield X, to_categorical(y_age, num_classes=NUM_CLASSES)# y_gender, y_age\n",
    "                    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "                    y_gender = []\n",
    "                    y_age = []\n",
    "                    cnt = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test_batch_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_generator(batch_size=10000):\n",
    "    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "    y_gender = []\n",
    "    y_age = []\n",
    "    cnt = 0\n",
    "    r = PickleWrapper.loadFromFile(os.path.join(args.DATA_DIR, 'data_gen/test1_creative_id.pkl'))\n",
    "    cc = 0\n",
    "    while True:\n",
    "        for uu in r:\n",
    "            print(cc)\n",
    "            cc += 1\n",
    "            for i, v in uu.items():\n",
    "#                 y_gender.append(gender2id[i])\n",
    "#                 y_age.append(age2id[i])\n",
    "                sents = v[0]\n",
    "                for sid, words in enumerate(sents):\n",
    "#                     t_ = words[:-1]\n",
    "#                     if len(t_) > 1:\n",
    "#                         random.shuffle(t_)\n",
    "                    words = pad_or_truncate(t_+[1], MAX_WORDS)\n",
    "                    X[cnt, sid] = words\n",
    "                cnt += 1\n",
    "                if cnt == batch_size:\n",
    "                    yield X\n",
    "                    X = np.zeros((batch_size, MAX_SENTS, MAX_WORDS))\n",
    "                    y_age = []\n",
    "                    cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = batch_generator(rtrain, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 91, 20)\n",
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for X, y_gender in a:\n",
    "    print(X.shape)\n",
    "    print(y_gender)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       ...,\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        1.000e+00],\n",
       "       [0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 2.194e+03,\n",
       "        1.000e+00]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 26, 128)           436835072 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 26, 200)           138000    \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 200)               226       \n",
      "=================================================================\n",
      "Total params: 436,973,298\n",
      "Trainable params: 138,226\n",
      "Non-trainable params: 436,835,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sent_inputs = Input(shape=(MAX_WORDS,), dtype=\"int32\")\n",
    "sent_emb = Embedding(input_dim=vocab_size,\n",
    "                     output_dim=WORD_EMBED_SIZE,\n",
    "                     weights=[E], \n",
    "                     trainable=False,\n",
    "                     mask_zero=True\n",
    "                    )(sent_inputs)\n",
    "\n",
    "sent_enc = Bidirectional(GRU(SENT_EMBED_SIZE,\n",
    "                            return_sequences=True))(sent_emb)\n",
    "\n",
    "sent_att = custom_attn.AttentionM()(sent_enc)\n",
    "\n",
    "sent_model = Model(inputs=sent_inputs, outputs=sent_att)\n",
    "sent_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 91, 26)]          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 91, 200)           436973298 \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 91, 100)           75600     \n",
      "_________________________________________________________________\n",
      "attention_m_1 (AttentionM)   (None, 100)               191       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 437,054,649\n",
      "Trainable params: 219,577\n",
      "Non-trainable params: 436,835,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "doc_inputs = Input(shape=(MAX_SENTS, MAX_WORDS), dtype=\"int32\")\n",
    "\n",
    "doc_emb = TimeDistributed(sent_model)(doc_inputs)\n",
    "\n",
    "doc_enc = Bidirectional(GRU(DOC_EMBED_SIZE,\n",
    "                           return_sequences=True))(doc_emb)\n",
    "\n",
    "doc_att = custom_attn.AttentionM()(doc_enc)\n",
    "# doc_att = AttentionM()(doc_enc)\n",
    "\n",
    "fc1_dropout = Dropout(0.2)(doc_att)\n",
    "fc1 = Dense(50, activation=\"relu\")(fc1_dropout)\n",
    "fc2_dropout = Dropout(0.2)(fc1)\n",
    "doc_pred = Dense(NUM_CLASSES, activation=\"softmax\")(fc2_dropout)\n",
    "\n",
    "model = Model(inputs=doc_inputs, outputs=doc_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 880 steps, validate for 10 steps\n",
      "Epoch 1/2\n",
      "880/880 [==============================] - 35240s 40s/step - loss: 1.5755 - accuracy: 0.3581 - val_loss: 1.4462 - val_accuracy: 0.4057\n",
      "Epoch 2/2\n",
      "474/880 [===============>..............] - ETA: 4:34:16 - loss: 1.4494 - accuracy: 0.4043"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batch_generator(rtrain, 1000),\n",
    "                   steps_per_epoch=880, epochs=2, validation_data=val_batch_generator(rtrain, 2000)\n",
    "                    , validation_steps=10,\n",
    "#                     workers=20,\n",
    "#                     use_multiprocessing=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 880 steps, validate for 10 steps\n",
      "Epoch 1/2\n",
      "  2/880 [..............................] - ETA: 5:08:24 - loss: 0.6899 - accuracy: 0.5185"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " RuntimeError: Your generator is NOT thread-safe. Keras requires a thread-safe generator when `use_multiprocessing=False, workers > 1`. \nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 990, in get\n    inputs = self.queue.get(block=True).get()\n\n  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n    raise self._value\n\n  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 924, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n\nValueError: generator already executing\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 1011, in get\n    'Your generator is NOT thread-safe. '\n\nRuntimeError: Your generator is NOT thread-safe. Keras requires a thread-safe generator when `use_multiprocessing=False, workers > 1`. \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_distributed_function_14041]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-96859198da2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                    \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m880\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#                     use_multiprocessing=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  RuntimeError: Your generator is NOT thread-safe. Keras requires a thread-safe generator when `use_multiprocessing=False, workers > 1`. \nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 990, in get\n    inputs = self.queue.get(block=True).get()\n\n  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n    raise self._value\n\n  File \"/root/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 924, in next_sample\n    return six.next(_SHARED_SEQUENCES[uid])\n\nValueError: generator already executing\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 236, in __call__\n    ret = func(*args)\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 789, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/root/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 1011, in get\n    'Your generator is NOT thread-safe. '\n\nRuntimeError: Your generator is NOT thread-safe. Keras requires a thread-safe generator when `use_multiprocessing=False, workers > 1`. \n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_distributed_function_14041]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batch_generator(rtrain, 1000),\n",
    "                   steps_per_epoch=880, epochs=2, validation_data=val_batch_generator(rtrain, 2000)\n",
    "                    , validation_steps=10,\n",
    "                    workers=20,\n",
    "#                     use_multiprocessing=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 880 steps, validate for 10 steps\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_batch_generator(rtrain, 1000),\n",
    "                   steps_per_epoch=880, epochs=2, validation_data=val_batch_generator(rtrain, 2000)\n",
    "                    , validation_steps=10,\n",
    "                    workers=20,\n",
    "                    use_multiprocessing=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1a1443cd50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(os.path.join(args.DATA_DIR, 'data_gen/model_age_6.weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_batch_generator(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "r = model.predict(t, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(args.DATA_DIR, 'data_gen/rs_age_arr.npy'), r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = pd.Series(np.argmax(r, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    357830\n",
       "4    256373\n",
       "3    126724\n",
       "5     99739\n",
       "1     89325\n",
       "7     19344\n",
       "6     15581\n",
       "0     14944\n",
       "8     12149\n",
       "9      7991\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.to_pickle(os.path.join(args.DATA_DIR, 'data_gen/rs_age.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = PickleWrapper.loadFromFile(os.path.join(args.DATA_DIR, 'data_gen/test1_creative_id.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "3131989    [[[1], [1], [1], [1], [1], [1], [1], [1], [1],...\n",
       "3131990    [[[1], [1], [1], [1], [973590, 1], [1], [1], [...\n",
       "3131994    [[[1], [1], [495715, 1], [1], [1], [536353, 12...\n",
       "3131995    [[[1], [1], [1], [54794, 1159, 1], [1], [1], [...\n",
       "3132000    [[[1], [1], [1], [6932, 1], [1], [1], [1], [1]...\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = pd.Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cc:\n",
    "    cs = cs.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf = cs.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3131989</td>\n",
       "      <td>[[[1], [1], [1], [1], [1], [1], [1], [1], [1],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3131990</td>\n",
       "      <td>[[[1], [1], [1], [1], [973590, 1], [1], [1], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3131994</td>\n",
       "      <td>[[[1], [1], [495715, 1], [1], [1], [536353, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3131995</td>\n",
       "      <td>[[[1], [1], [1], [54794, 1159, 1], [1], [1], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3132000</td>\n",
       "      <td>[[[1], [1], [1], [6932, 1], [1], [1], [1], [1]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         0\n",
       "3131989  [[[1], [1], [1], [1], [1], [1], [1], [1], [1],...\n",
       "3131990  [[[1], [1], [1], [1], [973590, 1], [1], [1], [...\n",
       "3131994  [[[1], [1], [495715, 1], [1], [1], [536353, 12...\n",
       "3131995  [[[1], [1], [1], [54794, 1159, 1], [1], [1], [...\n",
       "3132000  [[[1], [1], [1], [6932, 1], [1], [1], [1], [1]..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     357830\n",
       "5     256373\n",
       "4     126724\n",
       "6      99739\n",
       "2      89325\n",
       "8      19344\n",
       "7      15581\n",
       "1      14944\n",
       "9      12149\n",
       "10      7991\n",
       "Name: predicted_age, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf['predicted_age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf['predicted_age'] = rs.map(lambda x: str(int(x+1))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_gender = pd.read_pickle(os.path.join(args.DATA_DIR, 'data_gen/rs_gender.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf['predicted_gender'] = rs_gender.map(lambda x: str(int(x+1))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    711621\n",
       "2    288379\n",
       "Name: predicted_gender, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf['predicted_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3131989    NaN\n",
       "3131990    NaN\n",
       "3131994    NaN\n",
       "3131995    NaN\n",
       "3132000    NaN\n",
       "          ... \n",
       "3131979    NaN\n",
       "3131983    NaN\n",
       "3131984    NaN\n",
       "3131987    NaN\n",
       "3131988    NaN\n",
       "Name: predicted_gender, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csf['predicted_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "999995    0\n",
       "999996    0\n",
       "999997    1\n",
       "999998    0\n",
       "999999    0\n",
       "Length: 1000000, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "csf['predicted_age predicted_gender'.split()].reset_index().to_csv(os.path.join(args.DATA_DIR, 'data_gen/submission_dl.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
