{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp algo.seq.embeding.word2vec\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo-seq-embeding-word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估词向量\n",
    "https://blog.csdn.net/TimEcho/article/details/106281209\n",
    "\n",
    "* 评估方式一：降维。训练好的词向量，首先要进行降维，使用工具TSNE降维到2维，这样映射到二维空间，便于观察词向量训练后是否能将同类词聚集到一起\n",
    "* 评估方式二：相似度对比，选定两个词向量，计算相似度，然后与人工标注的相似度进行对比\n",
    "* 评估方式三：类比。计算woman和man的距离，然后在词库中找与girl距离跟woman和man距离相近的词\n",
    "\n",
    "* 打印loss: 选loss最低不再增长\n",
    "* 终极评估方式: 对于一些没有语义的向量，如item2vec，在训练的每n个epoch打印其最相近的n个items，如果基本稳定，不怎么变化，则说明训练好了\n",
    "\n",
    "# word embeding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## word2vec中skipgram的缺点\n",
    "\n",
    "1. 不考虑上下文，即同一个word只有一种向量表示，没有考虑一词多义的情况  \n",
    "解决方法：context-aware word embedding:ELmo或者BERT\n",
    "2. 窗口长度有限，  \n",
    "解决：类似于LM，使用RNN，LSTM来学习出词向量\n",
    "3. 无法考虑全局，  \n",
    "解决方法：全局模型（MF矩阵分解）\n",
    "4. 无法有效学习低频词向量，\n",
    "5. 未登录词，只在训练集出现已经训练好词向量，但是测试集没有，（OOV：out-of-vacabulary）  \n",
    "4,5，使用subword embedding解决\n",
    "6. 严格意义上的语序，解决：LM（RNN/LSTM）  \n",
    "7. 可解释性不足,解决：非欧式空间\n",
    "\n",
    "## subword: \n",
    "解决低频词、OOV, 根据已有词向量学习出新词的向量\n",
    "\n",
    "这种subword的方式是这样的：加入窗口大小n=4，将每个单词分成多个部分，每个部分包含4个character，  \n",
    "训练是我已然是采样skipgram模型，所以得到的词向量是subword这种形式。那么对于未登录词，完全可以通过找词库中的这种subword词向量来拼接到一个未登录词。并得到他的条件概率。  \n",
    "不过这种方法不适用于中文。  \n",
    "论文：enriching word embedding via wubword information\n",
    "\n",
    "当数据量很少时，可以考虑使用这种subword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\n",
    "\n",
    "## bag-of-words model\n",
    "This model transforms each document to a fixed-length vector of integers. For example, given the sentences:\n",
    "\n",
    "    John likes to watch movies. Mary likes movies too.\n",
    "\n",
    "    John also likes to watch football games. Mary hates football.\n",
    "\n",
    "The model outputs the vectors:\n",
    "\n",
    "    [1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]\n",
    "\n",
    "    [1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]\n",
    "\n",
    "Bag-of-words models are surprisingly effective, but have several weaknesses.\n",
    "\n",
    "首先，他们会丢失所有有关单词顺序的信息：“约翰喜欢玛丽”和“玛丽喜欢约翰”对应于相同的向量。 There is a solution: bag of n-grams models consider word phrases of length n to represent documents as fixed-length vectors to capture local word order but suffer from data sparsity and high dimensionality.\n",
    "\n",
    "其次，该模型不会尝试学习基础单词的含义，因此，向量之间的距离并不总是反映出含义上的差异。 \n",
    "\n",
    "Word2Vec模型解决了第二个问题。\n",
    "\n",
    "## the Word2Vec Model\n",
    "Word2Vec是一种更新的模型，它使用浅层神经网络将单词嵌入到低维向量空间中。 结果是一组词向量，其中在向量空间中靠在一起的向量根据上下文具有相似的含义，而彼此远离的词向量具有不同的含义。\n",
    "\n",
    "The are two versions of this model and Word2Vec class implements them both:\n",
    "\n",
    "### Skip-grams (SG)\n",
    "The Word2Vec Skip-gram model, for example, takes in pairs (word1, word2) generated by moving a window across text data, and trains a 1-hidden-layer neural network based on the synthetic task of given an input word, giving us a predicted probability distribution of nearby words to the input. A virtual one-hot encoding of words goes through a ‘projection layer’ to the hidden layer; these projection weights are later interpreted as the word embeddings. So if the hidden layer has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "### Continuous-bag-of-words (CBOW)\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It is also a 1-hidden-layer neural network. The synthetic training task now uses the average of multiple input context words, rather than a single word as in skip-gram, to predict the center word. Again, the projection weights that turn one-hot words into averageable vectors, of the same width as the hidden layer, are interpreted as the word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec代码实现\n",
    "## keras实现by 苏剑林\n",
    "https://kexue.fm/archives/4515"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim.models.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gensim==3.7.2\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U gensim\n",
    "!pip freeze | grep gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 默认参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word2Vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Word2Vec(\n",
    "        sentences=None,\n",
    "        corpus_file=None,\n",
    "        size=100,\n",
    "        alpha=0.025,\n",
    "        window=5,\n",
    "        min_count=5,\n",
    "        max_vocab_size=None,\n",
    "        sample=0.001,\n",
    "        seed=1,\n",
    "        workers=3,\n",
    "        min_alpha=0.0001,\n",
    "        sg=0,\n",
    "        hs=0,\n",
    "        negative=5,\n",
    "        ns_exponent=0.75,\n",
    "        cbow_mean=1,\n",
    "        hashfxn=<built-in function hash>,\n",
    "        iter=5,\n",
    "        null_word=0,\n",
    "        trim_rule=None,\n",
    "        sorted_vocab=1,\n",
    "        batch_words=10000,\n",
    "        compute_loss=False,\n",
    "        callbacks=(),\n",
    "        max_final_vocab=None,\n",
    "    )\n",
    "    \n",
    "* iter : int, optional 默认是5，要调\n",
    "    Number of iterations (epochs) over the corpus.\n",
    "* alpha : float, optional\n",
    "    The initial learning rate.\n",
    "* min_alpha : float, optional\n",
    "    Learning rate will linearly drop to `min_alpha` as training progresses.\n",
    "* workers : int, optional  默认是3，所以训练时要手动设置一下\n",
    "    Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "* min_count\n",
    "min_count用于修剪内部字典。 在十亿个单词的语料库中仅出现一次或两次的单词可能是无趣的错别字和垃圾。 此外，没有足够的数据来对这些词进行任何有意义的训练，因此最好忽略它们：\n",
    "\n",
    "min_count = 5的默认值\n",
    "* size\n",
    "size是gensim Word2Vec将单词映射到的N维空间的维数（N）。\n",
    "\n",
    "较大的值需要更多的训练数据，但可以产生更好（更准确）的模型。 合理的值在数十到数百之间。\n",
    "\n",
    "default value of size=100\n",
    "\n",
    "* window=5 : int, optional\n",
    "    Maximum distance between the current and predicted word within a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callbacks\n",
    "https://www.lizenghai.com/archives/16296.html\n",
    "\n",
    "https://radimrehurek.com/gensim/models/callbacks.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import gensim\n",
    "\n",
    "class EpochSaver(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    用于保存模型, 打印损失函数等等\n",
    "    \"\"\"\n",
    "    def __init__(self, savedir='./', save_name='word2vector.model'):\n",
    "\n",
    "        self.save_path = savedir+save_name\n",
    "\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.pre_loss = 0\n",
    "\n",
    "        self.best_loss = 999999999.9\n",
    "\n",
    "        self.since = time.time()\n",
    "    def on_epoch_begin(self, model):\n",
    "        pass\n",
    "    def on_epoch_end(self, model):\n",
    "        \n",
    "        self.epoch += 1\n",
    "        cum_loss = model.get_latest_training_loss() # 返回的是从第一个epoch累计的\n",
    "        if self.epoch % 1 == 0:\n",
    "\n",
    "            epoch_loss = cum_loss - self.pre_loss\n",
    "\n",
    "            time_taken = time.time() - self.since\n",
    "\n",
    "            print('Epoch %d, loss: %.2f, time: %dmin %ds' %\n",
    "\n",
    "                        (self.epoch, epoch_loss, time_taken//60, time_taken%60))\n",
    "\n",
    "            if self.best_loss > epoch_loss:\n",
    "\n",
    "                self.best_loss = epoch_loss\n",
    "\n",
    "                print('Better model.Best loss: %.2f' % self.best_loss)\n",
    "\n",
    "                model.save(self.save_path)\n",
    "\n",
    "                print('Model %s save done!' % self.save_path)\n",
    "\n",
    "        self.pre_loss = cum_loss\n",
    "\n",
    "        self.since = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Own Model\n",
    "这个语料库足够小，可以完全放入内存，但是我们将实现一个内存友好的迭代器，逐行读取它，以演示如何处理更大的语料库。\n",
    "\n",
    "如果我们想进行任何自定义的预处理，例如 解码非标准编码，小写字母，删除数字，提取命名实体……所有这些都可以在MyCorpus迭代器中完成，而word2vec不需要知道。 所需要的就是输入产生一个句子（另一个utf8单词列表）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "#             print(line[:5])\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hundreds',\n",
       " 'of',\n",
       " 'people',\n",
       " 'have',\n",
       " 'been',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'vacate',\n",
       " 'their',\n",
       " 'homes']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.simple_preprocess('Hundreds of people have been forced to vacate their homes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 100409.81, time: 0min 0s\n",
      "Better model.Best loss: 100409.81\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss: 94070.44, time: 0min 0s\n",
      "Better model.Best loss: 94070.44\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, loss: 86205.00, time: 0min 0s\n",
      "Better model.Best loss: 86205.00\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss: 80342.12, time: 0min 0s\n",
      "Better model.Best loss: 80342.12\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, loss: 73619.75, time: 0min 0s\n",
      "Better model.Best loss: 73619.75\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, loss: 69171.25, time: 0min 0s\n",
      "Better model.Best loss: 69171.25\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, loss: 66018.75, time: 0min 0s\n",
      "Better model.Best loss: 66018.75\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, loss: 63651.50, time: 0min 0s\n",
      "Better model.Best loss: 63651.50\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, loss: 62111.25, time: 0min 0s\n",
      "Better model.Best loss: 62111.25\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, loss: 61513.75, time: 0min 0s\n",
      "Better model.Best loss: 61513.75\n",
      "Model ./word2vector.model save done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "sentences = MyCorpus()\n",
    "model = Word2Vec(sentences=sentences, callbacks=[EpochSaver()], iter=50, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the model's neural weights from a sequence of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 1: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 2: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 3: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 4: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 5: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 6: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 7: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 8: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 9: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 10: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 11: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 12: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 13: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 14: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 15: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 16: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 17: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 18: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 19: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 20: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 21: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 22: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 23: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 24: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 25: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 26: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 27: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 28: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 29: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 30: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 31: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 32: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 33: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 34: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 35: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 36: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 37: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 38: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 39: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 40: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 41: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 42: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 43: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 44: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 45: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 46: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 47: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 48: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n",
      "Loss after epoch 49: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.46930772066116333), ('however', 0.41419118642807007), ('former', 0.41314512491226196)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1797065, 2907600)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences=sentences, total_examples=model.corpus_count, callbacks=[callback()], epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个训练周期内 回调没有变化, 手动更新。。。，总之回调函数没什么用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('george', 0.3772778809070587), ('source', 0.374118447303772), ('former', 0.36147093772888184)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36969128251075745), ('george', 0.3638962507247925), ('former', 0.3539872169494629)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.37612271308898926), ('george', 0.3636791706085205), ('former', 0.3475203812122345)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.37409070134162903), ('george', 0.36320599913597107), ('terror', 0.3548111021518707)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36942291259765625), ('george', 0.3611094355583191), ('terror', 0.3507077693939209)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.3696172833442688), ('george', 0.3632398843765259), ('terror', 0.3527523875236511)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36698445677757263), ('george', 0.36124473810195923), ('terror', 0.35444146394729614)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36159956455230713), ('george', 0.3597909212112427), ('terror', 0.35738757252693176)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36122196912765503), ('terror', 0.35700613260269165), ('george', 0.3567603528499603)]\n",
      "Loss after epoch 0: 0.0\n",
      "for word king: the top 3 sim user is [('source', 0.36049723625183105), ('terror', 0.3543187975883484), ('george', 0.3542329967021942)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model.train(sentences=sentences, total_examples=model.corpus_count, callbacks=[callback()], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RuntimeError: you must first build vocabulary before training the model\n",
    "# 原因:训练文本太小 min_count默认值为5，如果语料太小，导致每个词的发生频率都小于5，则会导致vocabulary为空。。。\n",
    "sentences = [\n",
    "    [\"cat\", \"say\", \"meow\"], \n",
    "    [\"dog\", \"say\", \"woof\"]]\n",
    "model = gensim.models.Word2Vec(sentences=sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03686245, -0.01609651, -0.01444744, -0.02135829, -0.00200862,\n",
       "       -0.01151453, -0.01819683,  0.02734437, -0.10053819, -0.05595972,\n",
       "        0.04234225,  0.04281876,  0.02587122,  0.01270954,  0.04601529,\n",
       "       -0.00835075,  0.00156381, -0.01310062,  0.00457986,  0.02177754,\n",
       "        0.02796555,  0.03658348, -0.00421377,  0.02298167,  0.00075962,\n",
       "       -0.01811693, -0.08794788, -0.01969494, -0.01617615, -0.01301005,\n",
       "        0.03622155, -0.02132978,  0.00818219, -0.01280667, -0.06247395,\n",
       "       -0.02782101,  0.01052102,  0.03244915,  0.055819  ,  0.02236952,\n",
       "       -0.02228366, -0.06680909, -0.03983621, -0.02890607,  0.03852952,\n",
       "       -0.05652092, -0.00395071, -0.065943  ,  0.0195525 ,  0.02234451,\n",
       "        0.02618746, -0.01053842, -0.01325279, -0.03100039, -0.03426435,\n",
       "        0.02069941, -0.04345337,  0.02748772, -0.02539084, -0.01945122,\n",
       "       -0.01035313,  0.05203196,  0.01739551, -0.02849312, -0.04863365,\n",
       "       -0.01096844, -0.06444025, -0.01036584, -0.04000191,  0.04583897,\n",
       "       -0.0053553 , -0.00509666, -0.01606082, -0.07653043,  0.0604446 ,\n",
       "       -0.00667824,  0.00838656, -0.05040137,  0.07151395, -0.00786852,\n",
       "        0.02645928,  0.05306596,  0.02914787,  0.03906055,  0.01238154,\n",
       "        0.00020839, -0.01395124,  0.01821121, -0.02370092, -0.01446467,\n",
       "       -0.01132251,  0.06112367,  0.07590397, -0.0048133 , -0.03360593,\n",
       "       -0.03753424, -0.01607151, -0.02337008, -0.03243359,  0.00209838],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king = model.wv['king']\n",
    "vec_king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01486553,  0.01823401, -0.02772865,  0.00213301,  0.0372683 ,\n",
       "        0.01642814,  0.04816883, -0.05448446,  0.01253152,  0.03404462,\n",
       "        0.01756212, -0.04840738, -0.03839137, -0.01304129, -0.03804687,\n",
       "        0.05305994, -0.00860955, -0.00836853,  0.00134603, -0.03344008,\n",
       "       -0.03039226, -0.03281286, -0.00623441, -0.02607584,  0.00408613,\n",
       "        0.04711006,  0.03532708, -0.0055987 , -0.00130932,  0.02229508,\n",
       "       -0.04697058, -0.02922403,  0.0131788 , -0.01622746,  0.05389683,\n",
       "       -0.02905632,  0.03431457,  0.01364054,  0.00634684, -0.01930137,\n",
       "       -0.01475715, -0.04367147, -0.00581169, -0.03634231,  0.01892559,\n",
       "       -0.01157352,  0.02849645,  0.00408916,  0.03510711, -0.0240911 ,\n",
       "       -0.03448397, -0.00420031, -0.06505472,  0.00562562, -0.03190516,\n",
       "       -0.01666111, -0.04189085,  0.07402997,  0.00904749, -0.03249473,\n",
       "        0.00972437,  0.03047183, -0.00820827, -0.02223486, -0.01516857,\n",
       "       -0.00403475, -0.02458509,  0.02097399, -0.00187658,  0.01206905,\n",
       "       -0.04879121, -0.01009979, -0.024553  , -0.02041692, -0.01424486,\n",
       "        0.03416541,  0.01465811, -0.02790837, -0.05651117,  0.03401321,\n",
       "        0.05107525, -0.01604857,  0.04182722, -0.01838509,  0.00617696,\n",
       "       -0.017543  ,  0.02919475,  0.06655695,  0.04709207,  0.06052168,\n",
       "        0.02376736, -0.01636989,  0.01506402,  0.00921484, -0.00102513,\n",
       "       -0.01343615, -0.0189462 , -0.00384656,  0.01540534, -0.04651833],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['king']  # removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = model.wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取最相近的词向量topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('highway', 0.9974420070648193), ('reported', 0.9973129630088806)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = model.wv.most_similar('king', topn=2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'king1' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-383d9b166514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'king1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'king1' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "r = model.wv.most_similar('king1', topn=2)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'highway': 0.9974420070648193, 'reported': 0.9973129630088806}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/Users/luoyonggui/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (highway, 0.9974420070648193)\n",
       "1    (reported, 0.9973129630088806)\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highway     0.997442\n",
       "reported    0.997313\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(dict(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('have', 0.9996969699859619), ('five', 0.9996781349182129), ('israeli', 0.9996719360351562), ('just', 0.9996703863143921), ('other', 0.999667763710022)]\n"
     ]
    }
   ],
   "source": [
    "# Print the 5 most similar words to “car” or “minivan”\n",
    "print(model.wv.most_similar(positive=['car', 'man'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:858: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'land'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取词汇表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': <gensim.models.keyedvectors.Vocab at 0x12039d278>,\n",
       " 'say': <gensim.models.keyedvectors.Vocab at 0x120392198>,\n",
       " 'meow': <gensim.models.keyedvectors.Vocab at 0x120392cf8>,\n",
       " 'dog': <gensim.models.keyedvectors.Vocab at 0x120392320>,\n",
       " 'woof': <gensim.models.keyedvectors.Vocab at 0x120392048>}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "say\n",
      "meow\n",
      "dog\n",
      "woof\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(model.wv.vocab):\n",
    "    if i == 10:\n",
    "        break\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing and loading models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model.\n",
    "This saved model can be loaded again using :func:`~gensim.models.word2vec.Word2Vec.load`, which supports\n",
    "online training and getting vectors for vocabulary words.\n",
    "\n",
    "如果model不大，则只会生成aa.model一个文件\n",
    "\n",
    "而如果model很大，则会生成aa.model、aa.model.trainables.syn1neg.npy和aa.model.wv.vectors.npy三个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.save('aa.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "new_model = Word2Vec.load('aa.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save KeyedVectors\n",
    "使用mdoel.wv.save以KededVectors实例的形式保存词向量文件，以该方式保存的模型丢失了完整的模型状态，无法再训练，保存的对象更小更快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.wv.save('aa.wv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv = KeyedVectors.load(\"aa.wv\", mmap='r')\n",
    "# wv['cat'] # numpy vector of a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save_word2vec_format\n",
    "Store the input-hidden weight matrix in the same format used by the original\n",
    "C word2vec-tool, for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('aa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.txt\n",
    "\n",
    "第一行 词汇数 词向量维度\n",
    "\n",
    "    5 100\n",
    "    say -0.0010033615 -0.0009983357 -0.0046261796 ...\n",
    "    cat 0.0037430483 -0.0044084494 -0.00355869 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# 文件大小会小一些\n",
    "model.wv.save_word2vec_format('aa.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv_from_text = KeyedVectors.load_word2vec_format(\"aa.txt\", binary=False) # C text format\n",
    "wv_from_bin = KeyedVectors.load_word2vec_format(\"aa.bin\", binary=True) # C bin format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['say', 'cat', 'meow', 'dog', 'woof']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_bin.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'say': <gensim.models.keyedvectors.Vocab at 0x11f6e04e0>,\n",
       " 'cat': <gensim.models.keyedvectors.Vocab at 0x120299f28>,\n",
       " 'meow': <gensim.models.keyedvectors.Vocab at 0x120299a58>,\n",
       " 'dog': <gensim.models.keyedvectors.Vocab at 0x120299eb8>,\n",
       " 'woof': <gensim.models.keyedvectors.Vocab at 0x120299e80>}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_bin.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_bin.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00336154e-03, -9.98335658e-04, -4.62617958e-03,\n",
       "        -3.38307256e-03, -3.09544732e-03,  1.51311210e-03,\n",
       "         3.80300032e-03,  3.18969460e-03,  7.81343377e-04,\n",
       "        -2.46190885e-03,  2.17640679e-03, -3.25980550e-03,\n",
       "         1.43450543e-05,  4.70067002e-03,  1.95618439e-03,\n",
       "         4.28239303e-03,  3.11228703e-03,  1.51620491e-03,\n",
       "        -1.50276057e-03, -4.60313837e-04,  2.48095999e-03,\n",
       "        -3.22831911e-03, -3.85779800e-04,  3.56054096e-03,\n",
       "        -3.30647174e-03, -1.74928561e-03,  8.98306957e-04,\n",
       "        -3.42513435e-03,  3.91588220e-03, -1.15593395e-03,\n",
       "         3.85119743e-03, -3.03606829e-03,  1.79845863e-03,\n",
       "        -4.82477993e-03,  3.07267765e-03, -2.03650724e-03,\n",
       "         3.78798088e-03,  1.83291547e-03, -2.65652593e-03,\n",
       "         1.30606335e-04,  1.59174844e-03,  2.87242723e-03,\n",
       "        -4.25131060e-03,  3.60778859e-03, -4.82053263e-03,\n",
       "        -5.82585286e-04, -3.77888908e-03,  6.24802196e-05,\n",
       "         2.50778510e-04,  1.17574842e-03,  2.87227868e-03,\n",
       "         1.91963674e-03, -1.13106903e-03,  2.13767309e-03,\n",
       "         4.99653816e-03, -4.74167056e-03,  1.23905495e-03,\n",
       "         1.21991127e-03,  2.29018973e-03,  2.56114663e-03,\n",
       "         3.43530113e-03, -6.86111161e-05, -3.20219412e-03,\n",
       "         2.01382884e-03, -3.52587737e-03,  2.17830017e-03,\n",
       "         3.90839716e-03, -2.86897528e-03,  3.50393751e-03,\n",
       "        -4.93930513e-03,  4.03408892e-03,  2.03908561e-03,\n",
       "        -4.44774237e-03, -9.40738537e-04, -4.27086139e-04,\n",
       "         8.33079452e-04, -2.66960077e-03, -1.89078634e-03,\n",
       "         3.43453465e-03, -2.77509657e-03, -6.80529956e-06,\n",
       "        -4.84125922e-03,  1.70634314e-03,  2.51891879e-06,\n",
       "        -3.68656125e-04,  3.94969014e-03,  3.75141576e-03,\n",
       "         1.54440443e-03,  4.63962881e-03, -2.00333330e-03,\n",
       "        -5.90287556e-04, -3.22648138e-03, -4.97552799e-03,\n",
       "         4.74738830e-04, -1.81210018e-03, -4.18368913e-03,\n",
       "         3.45529383e-03, -1.22078042e-03, -2.19903048e-03,\n",
       "         3.55265453e-04],\n",
       "       [ 3.74304829e-03, -4.40844940e-03, -3.55868996e-03,\n",
       "        -2.10015755e-03,  1.26162008e-03, -2.82121170e-03,\n",
       "        -1.95046258e-03,  7.40597898e-04,  3.11787939e-03,\n",
       "        -4.46490478e-03, -4.00897441e-03,  6.80610072e-04,\n",
       "         3.31253745e-03,  3.46108689e-03,  4.16817702e-03,\n",
       "         2.46615242e-03, -3.16035049e-03, -2.66160676e-03,\n",
       "        -3.67510784e-03, -1.83009682e-03, -2.96183047e-03,\n",
       "        -3.98977939e-03,  2.95248977e-03, -9.13635158e-05,\n",
       "         2.68919073e-04,  3.92539863e-04,  4.66983533e-04,\n",
       "        -4.74751741e-03,  1.62268989e-03, -3.75506585e-03,\n",
       "        -7.79732945e-04,  4.30948474e-03,  2.98316078e-03,\n",
       "         3.96726327e-03,  1.61506014e-03, -4.84898966e-03,\n",
       "        -4.90420545e-03, -2.20354274e-03,  1.05985953e-03,\n",
       "        -4.43321915e-04,  3.53338517e-04, -3.76034249e-03,\n",
       "         1.94095494e-03,  4.37277835e-03,  3.19519104e-03,\n",
       "         3.18080001e-03,  4.00262792e-03, -1.12074823e-03,\n",
       "         4.75680782e-03, -1.00890221e-03, -1.30661717e-03,\n",
       "         7.42339529e-04,  2.64482154e-03, -3.58798285e-03,\n",
       "        -4.14323155e-03, -2.25847223e-04,  1.74742343e-03,\n",
       "        -2.27823295e-03,  1.38348492e-04, -2.39030737e-03,\n",
       "        -5.80068678e-04, -3.84719693e-03,  4.89630364e-03,\n",
       "        -2.28579086e-03, -6.46136235e-04,  4.27413359e-03,\n",
       "        -4.81093489e-03, -2.85331532e-03,  4.17081965e-03,\n",
       "        -4.50722408e-03,  1.92120997e-03,  2.17912626e-03,\n",
       "        -1.85300340e-03,  2.66319141e-03, -3.31183849e-03,\n",
       "         3.89673770e-03, -1.66802027e-03, -4.27112496e-03,\n",
       "         8.28885299e-04,  2.38689920e-03,  1.82575302e-03,\n",
       "        -4.23216959e-03,  2.75214273e-03,  4.14010021e-04,\n",
       "        -2.18362734e-03,  1.17796182e-04, -3.23682791e-03,\n",
       "         1.38794794e-03,  8.27484997e-04,  4.77363681e-03,\n",
       "        -2.72964407e-03,  4.28191107e-03,  1.37682946e-03,\n",
       "         4.10231529e-03, -1.08444213e-03,  2.02565105e-03,\n",
       "         3.52285244e-03, -1.37940771e-03, -1.82346185e-03,\n",
       "        -2.28287838e-03],\n",
       "       [ 4.85166674e-03, -2.53974576e-04,  4.90596378e-03,\n",
       "        -4.20613587e-03, -5.94370940e-04,  9.52506205e-04,\n",
       "        -3.26526957e-03,  4.38342383e-03, -4.74426197e-03,\n",
       "         1.88488094e-03, -2.29171361e-04, -4.23146598e-03,\n",
       "         7.48996157e-04,  2.63821625e-04, -2.58001243e-03,\n",
       "        -2.77272006e-03,  2.83399248e-04, -2.81138835e-03,\n",
       "         4.02210560e-03,  7.22670404e-04,  4.96841222e-03,\n",
       "        -1.68645103e-03, -4.94101411e-03, -3.65294516e-03,\n",
       "         4.81980247e-03,  4.12930676e-04,  1.46878374e-04,\n",
       "        -4.25761146e-03, -2.26493576e-03,  3.10549326e-03,\n",
       "         9.27368761e-04, -6.92996487e-04, -2.77822930e-03,\n",
       "         7.96269393e-04,  1.02194410e-03, -2.96917208e-03,\n",
       "         1.65619201e-03,  4.47936030e-03,  4.60890681e-03,\n",
       "         1.60692527e-03,  1.08023849e-03, -1.95747544e-03,\n",
       "        -4.29918990e-03, -2.16083322e-03,  1.33785664e-03,\n",
       "         2.30296445e-03, -2.82946276e-03,  3.72547889e-03,\n",
       "         4.20235191e-03,  4.10266733e-03,  4.47190786e-03,\n",
       "         3.21046868e-03,  4.17507393e-03, -1.97051023e-03,\n",
       "        -4.78746369e-03, -1.40021811e-03,  4.34418628e-03,\n",
       "         4.65077086e-04, -4.64172754e-03,  4.30572405e-03,\n",
       "         1.64187470e-04,  8.59858468e-04,  1.00488740e-03,\n",
       "         3.10022081e-03,  4.90837777e-03, -3.83128109e-03,\n",
       "        -4.26854985e-03,  1.12955470e-03,  2.42803805e-03,\n",
       "         2.78732693e-03,  4.70635388e-03,  2.92628724e-03,\n",
       "        -4.87279147e-04, -2.67322920e-03, -2.01475178e-03,\n",
       "        -2.51724129e-03, -3.28697450e-03,  1.72504981e-03,\n",
       "         1.90799194e-03, -2.37179594e-03, -4.39585047e-03,\n",
       "         4.41712653e-03, -2.94483500e-03, -4.43168636e-03,\n",
       "         3.06568877e-03,  2.83594872e-03,  3.91969876e-03,\n",
       "         2.95410911e-03,  1.37401593e-03, -2.92102597e-03,\n",
       "        -1.36501610e-03,  9.98068834e-04,  2.35896697e-03,\n",
       "        -4.37490642e-03, -1.73010980e-03,  2.96467828e-04,\n",
       "        -1.22782926e-03, -2.81941239e-03, -4.96259239e-03,\n",
       "         3.55972006e-04],\n",
       "       [ 8.31162615e-04,  2.99322093e-03, -2.06766301e-03,\n",
       "         1.37463817e-03, -3.90627515e-03,  2.23978981e-03,\n",
       "         1.39148615e-03,  3.66583909e-03,  4.56215162e-03,\n",
       "        -6.97147974e-04, -3.22765508e-03,  3.02766822e-03,\n",
       "        -3.96806048e-03,  9.08122631e-04, -1.05047668e-03,\n",
       "         3.10343481e-03, -1.04972487e-03,  3.43942852e-03,\n",
       "        -4.49447939e-03,  4.92101535e-03, -3.05259903e-03,\n",
       "        -3.92466597e-03, -4.83549578e-04, -2.48664408e-04,\n",
       "         7.28132902e-04, -4.22507897e-03,  2.54561589e-03,\n",
       "         1.95067993e-03, -1.52156665e-03,  2.37374171e-03,\n",
       "        -2.99756788e-03,  1.73009164e-03,  4.52704774e-03,\n",
       "        -7.63812917e-04, -1.27900054e-03,  1.16692833e-03,\n",
       "         4.10416489e-03,  1.18214644e-04,  2.35830713e-03,\n",
       "        -1.24515465e-03,  1.90202799e-03,  3.75004997e-03,\n",
       "         3.12787690e-03, -5.90370793e-04,  4.59536584e-03,\n",
       "        -2.53581628e-03, -2.55179475e-03,  3.21401283e-03,\n",
       "         8.70555115e-04,  2.15458072e-04, -2.57380167e-03,\n",
       "         1.88131642e-03, -8.74720339e-04, -4.21083905e-03,\n",
       "         3.01272399e-03,  3.46311787e-03,  1.94122852e-03,\n",
       "        -3.33991414e-03, -2.16041063e-03, -4.87115793e-03,\n",
       "        -3.74253956e-03, -2.68288213e-03,  9.59798228e-04,\n",
       "        -2.40018615e-03, -2.12186045e-04,  4.82595898e-03,\n",
       "         6.68908528e-04,  3.14524584e-03, -9.72056223e-05,\n",
       "        -3.27931019e-04,  9.03790700e-04, -2.11928040e-03,\n",
       "        -2.64640991e-03, -1.16252562e-03,  2.84838118e-03,\n",
       "         2.48851627e-03,  6.33864256e-04,  2.49893288e-03,\n",
       "         2.61335098e-03,  4.90317936e-04, -8.20588088e-04,\n",
       "         2.09405669e-03,  4.00222652e-03,  9.69839690e-04,\n",
       "         3.67882545e-03,  4.43303306e-03,  3.53766629e-03,\n",
       "        -8.39408254e-04,  7.42639182e-04,  2.90398463e-03,\n",
       "        -8.96316051e-05, -1.80608057e-03, -4.34422080e-04,\n",
       "         2.02660402e-03,  4.29307856e-03, -3.40442592e-03,\n",
       "         2.82509997e-03,  3.27127404e-03,  2.84865941e-03,\n",
       "        -7.43332785e-04],\n",
       "       [-2.67319544e-03, -4.26462712e-03, -2.48376536e-03,\n",
       "         8.09555582e-04,  1.02233887e-03,  1.63374445e-03,\n",
       "         4.54072980e-03,  1.54256017e-03, -1.29456015e-03,\n",
       "         1.77741144e-03, -2.23220792e-03, -7.26195693e-04,\n",
       "         9.38983692e-04,  2.72230129e-03,  3.68901389e-03,\n",
       "        -4.16652532e-03,  7.82855263e-04, -3.78757901e-03,\n",
       "         2.54964945e-03,  2.64121499e-03,  1.59354694e-03,\n",
       "        -1.72488415e-03,  2.35051941e-03,  1.87397143e-03,\n",
       "        -1.37843052e-03,  2.84778071e-03, -1.14158494e-03,\n",
       "         2.96234852e-03, -4.10135137e-03, -2.09266227e-03,\n",
       "         1.48821762e-03,  1.79392542e-03,  2.87911366e-03,\n",
       "        -4.50350204e-03,  2.02377979e-03, -4.31476301e-03,\n",
       "        -2.80121167e-04,  1.03490602e-03, -5.46418363e-04,\n",
       "        -1.26168801e-04,  1.71908003e-03,  1.85447652e-03,\n",
       "         1.61938067e-03, -3.69136035e-03,  1.26400881e-03,\n",
       "         2.73089274e-03, -4.61013522e-03, -1.30196079e-03,\n",
       "        -3.33552761e-03,  3.68834473e-03,  2.40196823e-03,\n",
       "        -3.85880889e-03,  1.22936629e-03, -3.40178562e-03,\n",
       "        -1.81669521e-03, -4.03849268e-03, -2.62114033e-03,\n",
       "        -4.47514793e-03,  5.02325129e-04, -1.40432129e-03,\n",
       "        -7.98255263e-04, -3.41966259e-03, -2.86621461e-03,\n",
       "        -4.07048734e-03, -4.00690967e-03,  4.76916134e-03,\n",
       "         4.10965504e-03,  3.60254035e-03,  3.66497901e-03,\n",
       "        -3.13882576e-03,  8.90677387e-04, -2.03523086e-03,\n",
       "         1.29593315e-03,  4.14986117e-03,  4.12883423e-03,\n",
       "        -3.44557432e-03,  2.73484411e-03,  2.11017745e-04,\n",
       "        -5.33495040e-04,  2.68011377e-03,  1.58756549e-04,\n",
       "        -8.55792081e-04, -4.19583730e-03,  4.08699270e-03,\n",
       "        -3.05461884e-03,  4.92676627e-03,  3.78713361e-03,\n",
       "        -4.97456128e-03, -4.60112235e-03, -3.50389071e-03,\n",
       "         2.63334205e-03, -3.20176501e-03,  4.51139081e-03,\n",
       "        -2.72644629e-05,  1.92842376e-03, -1.52600452e-03,\n",
       "        -2.00012419e-03, -1.02793169e-03,  9.64789186e-04,\n",
       "        -4.18165140e-03]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_bin.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.7430483e-03, -4.4084494e-03, -3.5586900e-03, -2.1001576e-03,\n",
       "        1.2616201e-03, -2.8212117e-03, -1.9504626e-03,  7.4059790e-04,\n",
       "        3.1178794e-03, -4.4649048e-03, -4.0089744e-03,  6.8061007e-04,\n",
       "        3.3125374e-03,  3.4610869e-03,  4.1681770e-03,  2.4661524e-03,\n",
       "       -3.1603505e-03, -2.6616068e-03, -3.6751078e-03, -1.8300968e-03,\n",
       "       -2.9618305e-03, -3.9897794e-03,  2.9524898e-03, -9.1363516e-05,\n",
       "        2.6891907e-04,  3.9253986e-04,  4.6698353e-04, -4.7475174e-03,\n",
       "        1.6226899e-03, -3.7550658e-03, -7.7973295e-04,  4.3094847e-03,\n",
       "        2.9831608e-03,  3.9672633e-03,  1.6150601e-03, -4.8489897e-03,\n",
       "       -4.9042054e-03, -2.2035427e-03,  1.0598595e-03, -4.4332191e-04,\n",
       "        3.5333852e-04, -3.7603425e-03,  1.9409549e-03,  4.3727783e-03,\n",
       "        3.1951910e-03,  3.1808000e-03,  4.0026279e-03, -1.1207482e-03,\n",
       "        4.7568078e-03, -1.0089022e-03, -1.3066172e-03,  7.4233953e-04,\n",
       "        2.6448215e-03, -3.5879829e-03, -4.1432315e-03, -2.2584722e-04,\n",
       "        1.7474234e-03, -2.2782329e-03,  1.3834849e-04, -2.3903074e-03,\n",
       "       -5.8006868e-04, -3.8471969e-03,  4.8963036e-03, -2.2857909e-03,\n",
       "       -6.4613624e-04,  4.2741336e-03, -4.8109349e-03, -2.8533153e-03,\n",
       "        4.1708197e-03, -4.5072241e-03,  1.9212100e-03,  2.1791263e-03,\n",
       "       -1.8530034e-03,  2.6631914e-03, -3.3118385e-03,  3.8967377e-03,\n",
       "       -1.6680203e-03, -4.2711250e-03,  8.2888530e-04,  2.3868992e-03,\n",
       "        1.8257530e-03, -4.2321696e-03,  2.7521427e-03,  4.1401002e-04,\n",
       "       -2.1836273e-03,  1.1779618e-04, -3.2368279e-03,  1.3879479e-03,\n",
       "        8.2748500e-04,  4.7736368e-03, -2.7296441e-03,  4.2819111e-03,\n",
       "        1.3768295e-03,  4.1023153e-03, -1.0844421e-03,  2.0256510e-03,\n",
       "        3.5228524e-03, -1.3794077e-03, -1.8234618e-03, -2.2828784e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_from_bin['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = wv_from_bin.get_keras_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.7430483e-03, -4.4084494e-03, -3.5586900e-03, -2.1001576e-03,\n",
       "        1.2616201e-03, -2.8212117e-03, -1.9504626e-03,  7.4059790e-04,\n",
       "        3.1178794e-03, -4.4649048e-03, -4.0089744e-03,  6.8061007e-04,\n",
       "        3.3125374e-03,  3.4610869e-03,  4.1681770e-03,  2.4661524e-03,\n",
       "       -3.1603505e-03, -2.6616068e-03, -3.6751078e-03, -1.8300968e-03,\n",
       "       -2.9618305e-03, -3.9897794e-03,  2.9524898e-03, -9.1363516e-05,\n",
       "        2.6891907e-04,  3.9253986e-04,  4.6698353e-04, -4.7475174e-03,\n",
       "        1.6226899e-03, -3.7550658e-03, -7.7973295e-04,  4.3094847e-03,\n",
       "        2.9831608e-03,  3.9672633e-03,  1.6150601e-03, -4.8489897e-03,\n",
       "       -4.9042054e-03, -2.2035427e-03,  1.0598595e-03, -4.4332191e-04,\n",
       "        3.5333852e-04, -3.7603425e-03,  1.9409549e-03,  4.3727783e-03,\n",
       "        3.1951910e-03,  3.1808000e-03,  4.0026279e-03, -1.1207482e-03,\n",
       "        4.7568078e-03, -1.0089022e-03, -1.3066172e-03,  7.4233953e-04,\n",
       "        2.6448215e-03, -3.5879829e-03, -4.1432315e-03, -2.2584722e-04,\n",
       "        1.7474234e-03, -2.2782329e-03,  1.3834849e-04, -2.3903074e-03,\n",
       "       -5.8006868e-04, -3.8471969e-03,  4.8963036e-03, -2.2857909e-03,\n",
       "       -6.4613624e-04,  4.2741336e-03, -4.8109349e-03, -2.8533153e-03,\n",
       "        4.1708197e-03, -4.5072241e-03,  1.9212100e-03,  2.1791263e-03,\n",
       "       -1.8530034e-03,  2.6631914e-03, -3.3118385e-03,  3.8967377e-03,\n",
       "       -1.6680203e-03, -4.2711250e-03,  8.2888530e-04,  2.3868992e-03,\n",
       "        1.8257530e-03, -4.2321696e-03,  2.7521427e-03,  4.1401002e-04,\n",
       "       -2.1836273e-03,  1.1779618e-04, -3.2368279e-03,  1.3879479e-03,\n",
       "        8.2748500e-04,  4.7736368e-03, -2.7296441e-03,  4.2819111e-03,\n",
       "        1.3768295e-03,  4.1023153e-03, -1.0844421e-03,  2.0256510e-03,\n",
       "        3.5228524e-03, -1.3794077e-03, -1.8234618e-03, -2.2828784e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wv_from_text['cat']\n",
    "# wv_from_bin['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fasttext\n",
    "https://mp.weixin.qq.com/s/MmikAgOSz7k9ncGkWIlMbA\n",
    "\n",
    "## fastText 在不同语境中至少有两个含义\n",
    "1. 在文章 Bag of Tricks for Efficient Text Classification [1] 中，fastText 是作者提出的文本分类器的名字。与 sub-word 无关！也不是新的词嵌入训练模型！是 word2vec 中 CBOW 模型的简单变种。\n",
    "2. 作为 Facebook 开源包，fastText [6] 是用来训练词嵌入或句嵌入的，其不仅包括 1 中论文的代码实现，还包括 Enriching Word Vectors with Subword Information [2] 及 FastText.zip: Compressing text classification models [3] 两文的代码实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类语义下的fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Tricks for Efficient Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"450\"\n",
       "            src=\"https://arxiv.org/pdf/1607.01759.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x106811828>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://arxiv.org/pdf/1607.01759.pdf', width=1000, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText.zip: Compressing text classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"450\"\n",
       "            src=\"https://arxiv.org/pdf/1612.03651.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x103b0a3c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://arxiv.org/pdf/1612.03651.pdf', width=1000, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character-level Convolutional Networks for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"450\"\n",
       "            src=\"https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x103b00da0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf', width=1000, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## embedding语义下的fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriching Word Vectors with Subword Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"450\"\n",
       "            src=\"https://arxiv.org/pdf/1607.04606.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1068116d8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://arxiv.org/pdf/1607.04606.pdf', width=1000, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim-fasttext\n",
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastText(\n",
    "    sentences=None,\n",
    "    corpus_file=None,\n",
    "    sg=0,\n",
    "    hs=0,\n",
    "    size=100,\n",
    "    alpha=0.025,\n",
    "    window=5,\n",
    "    min_count=5,\n",
    "    max_vocab_size=None,\n",
    "    word_ngrams=1,\n",
    "    # {1,0}, optional\n",
    "    # If 1, uses enriches word vectors with subword(n-grams) information.\n",
    "    # If 0, this is equivalent to :class:`~gensim.models.word2vec.Word2Vec`.\n",
    "    sample=0.001,\n",
    "    seed=1,\n",
    "    workers=3,\n",
    "    min_alpha=0.0001,\n",
    "    negative=5,\n",
    "    ns_exponent=0.75,\n",
    "    cbow_mean=1,\n",
    "    hashfxn=<built-in function hash>,\n",
    "    iter=5,  # Number of epochs， 一般显然是不够的\n",
    "    null_word=0,\n",
    "    min_n=3,  # min length of char ngrams\n",
    "    max_n=6,\n",
    "    sorted_vocab=1,\n",
    "    bucket=2000000,  # number of buckets used for hashing ngrams \n",
    "    trim_rule=None,\n",
    "    batch_words=10000,\n",
    "    callbacks=(),\n",
    "    compatible_hash=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training 中文\n",
    "训练速度比word2vec要慢很多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "sentences = [[\"你好\", \"世界\", \"快乐\"], [\"好人\", \"世代\", \"快速\"]]\n",
    "\n",
    "model = FastText(sentences, min_count=1, min_n=2, iter=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.9822402e-03,  2.4169697e-03,  1.7187260e-03, -2.2653495e-03,\n",
       "        3.2119157e-03,  4.2951079e-03, -2.7774605e-03,  2.5285247e-03,\n",
       "        7.1119861e-04, -2.2702373e-03, -2.2216819e-03, -1.1484689e-03,\n",
       "       -5.0927966e-04,  2.7783182e-03, -3.7633646e-03,  2.2833713e-03,\n",
       "        2.8870531e-04,  2.9109684e-03, -9.9741039e-04,  9.3552069e-04,\n",
       "        6.5907091e-04, -1.2434857e-03, -4.8777787e-05, -5.5110501e-03,\n",
       "       -8.8064518e-04, -1.8348387e-03, -3.1964940e-03,  1.9632792e-03,\n",
       "        2.2461899e-03, -2.3505124e-03, -5.6509962e-03,  2.8363969e-03,\n",
       "       -8.7185681e-04,  9.0928376e-04,  3.1893721e-03, -2.6449324e-03,\n",
       "        4.7927522e-04, -2.9875131e-03,  3.3288699e-04, -2.3074101e-03,\n",
       "       -1.2953918e-03, -8.3305809e-04,  4.7961317e-04, -2.4373434e-03,\n",
       "       -2.1793812e-03,  8.0079201e-04, -3.0157524e-03,  4.0204329e-03,\n",
       "        3.0183580e-04,  1.8538638e-03, -2.0454575e-03, -2.6678795e-03,\n",
       "        1.1443186e-03, -3.0163454e-03,  7.0191745e-04,  5.2529224e-03,\n",
       "       -4.1715396e-04,  2.6155575e-03, -1.5787049e-05, -2.6378669e-03,\n",
       "       -4.0177507e-03,  3.0135855e-04, -2.6271401e-03, -7.6248043e-04,\n",
       "       -1.5874549e-03, -6.9245277e-04, -3.5787441e-04, -1.8292440e-05,\n",
       "        2.6118958e-03, -1.1617452e-03, -4.5009218e-03,  1.6276392e-03,\n",
       "       -2.2793957e-03, -1.5171530e-03,  7.6165556e-06,  4.6226350e-03,\n",
       "        8.9755811e-04, -5.6473352e-04, -1.8008711e-03,  2.1703136e-03,\n",
       "       -1.6997193e-03, -4.7692214e-03,  1.7985804e-03,  2.2161599e-04,\n",
       "       -2.8584923e-03, -1.3434608e-03, -1.6425215e-03, -1.4214923e-03,\n",
       "       -2.4271790e-04,  3.4046855e-03,  9.1542536e-04, -1.7788043e-03,\n",
       "        8.9269958e-04,  2.8674130e-03,  4.9870270e-03, -8.6791202e-04,\n",
       "       -3.2797146e-03, -1.4149909e-03, -8.1546727e-04, -1.2710411e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['世界']  # get vector for word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.0318054e-04,  2.6340729e-03, -2.4031913e-03,  5.1210332e-04,\n",
       "       -6.4614485e-04,  1.4889885e-03,  1.5180273e-03, -9.9588011e-04,\n",
       "       -1.4411961e-03,  8.9846511e-04,  3.5744504e-04,  1.5467522e-03,\n",
       "        3.7019928e-03, -1.4805131e-03, -2.1489430e-05, -1.8503825e-03,\n",
       "        1.4395656e-03, -5.2286941e-04, -2.9034005e-03,  1.6823788e-03,\n",
       "       -2.2158846e-03, -9.8364311e-04, -9.2589605e-04, -1.2630870e-03,\n",
       "        5.3450739e-04, -8.9164951e-04,  2.0512906e-03, -3.8826707e-04,\n",
       "        1.5873264e-03, -2.3737226e-03, -1.0957335e-03,  1.7603323e-03,\n",
       "        3.6992301e-04,  2.5232488e-03,  8.5212628e-04, -1.5399997e-03,\n",
       "       -1.7697698e-03,  1.4537339e-03,  5.7253614e-04, -3.4134286e-05,\n",
       "       -1.7359739e-03,  1.1944456e-03, -4.4834069e-03,  2.2543869e-03,\n",
       "       -7.1508944e-04,  9.7015040e-04,  4.5475870e-04,  9.7663095e-04,\n",
       "        2.4216895e-03,  1.8361442e-03,  4.1975899e-04,  1.5667530e-03,\n",
       "       -1.7469459e-03, -1.3007789e-03,  2.0048935e-03,  2.3161517e-03,\n",
       "        3.9505521e-03,  1.0725192e-03, -9.1201036e-05,  1.6107850e-03,\n",
       "        6.4673071e-04,  2.7299072e-03,  2.3241835e-03,  1.1502228e-03,\n",
       "        2.4456407e-03, -1.3905815e-03,  2.8663551e-04,  5.9688842e-04,\n",
       "       -1.8903059e-03,  7.8507575e-05, -3.8736966e-06,  4.6173899e-04,\n",
       "       -1.0837999e-03,  1.4794004e-04, -4.7290412e-04, -1.2483649e-03,\n",
       "       -1.0078526e-03, -6.1469380e-04, -2.7126891e-03,  1.2444832e-03,\n",
       "        1.5321224e-03,  1.3372379e-03,  3.7350676e-03,  2.2223264e-03,\n",
       "        1.9053114e-03,  1.5736684e-03,  2.0805413e-03,  3.1088267e-03,\n",
       "       -1.6512051e-04, -2.5474612e-04, -3.1758417e-04, -1.4927707e-03,\n",
       "        9.9493295e-04, -1.3637083e-03,  1.3676777e-03,  2.6813645e-03,\n",
       "       -1.2204890e-03,  1.8699794e-03,  2.5168009e-04, -2.5683784e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['快快乐乐']  # get vector for out-of-vocab word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43810502"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"快乐\", \"快快乐乐\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00832216"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"世界\", \"快快乐乐\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Set file names for train and test data\n",
    "corpus_file = datapath('lee_background.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/gensim/test/test_data/lee_background.cor'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FT_gensim(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "model.build_vocab(corpus_file=corpus_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59890"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.train(\n",
    "    corpus_file=corpus_file, epochs=model.epochs,\n",
    "    total_examples=model.corpus_count, total_words=model.corpus_total_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.fasttext.FastText object at 0x11681b518>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests if word present in vocab\n",
    "'night' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'nights' in model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.71200413e-02,  1.05707003e-02, -5.89070261e-01,  5.15045047e-01,\n",
       "        5.87517440e-01, -3.32078636e-01, -1.90413103e-01, -3.94908749e-02,\n",
       "        4.24223274e-01,  3.16444933e-01, -6.34695113e-01, -2.14536432e-02,\n",
       "       -6.66504323e-01,  4.09089714e-01,  3.09547037e-01, -5.73672540e-02,\n",
       "       -1.86798245e-01,  2.07086176e-01,  2.25862935e-01, -3.73620391e-01,\n",
       "       -2.31027037e-01,  3.02217811e-01, -3.93239588e-01,  1.71807073e-02,\n",
       "       -8.23755801e-01,  7.31919646e-01,  1.30469099e-01,  1.77326202e-01,\n",
       "        4.04274732e-01,  8.38539843e-03, -6.41942382e-01,  2.52658665e-01,\n",
       "        8.58276263e-02, -5.00359297e-01,  4.58392501e-01,  1.12920761e-01,\n",
       "       -1.48069695e-01, -7.77938142e-02,  4.22724515e-01,  2.39092767e-01,\n",
       "       -5.21457894e-03, -7.26774260e-02,  3.92118275e-01, -7.20630363e-02,\n",
       "        1.19034253e-01,  1.91644192e-01, -1.39423281e-01,  2.18378246e-01,\n",
       "       -3.35901529e-02, -3.93209457e-01, -5.56832254e-01, -5.41895211e-01,\n",
       "        5.90641387e-02, -2.03276053e-04,  4.03446287e-01, -7.85883307e-01,\n",
       "       -1.13854118e-01, -1.75213501e-01,  2.26113908e-02, -3.04364990e-02,\n",
       "        1.96977288e-01, -1.09108604e-01, -5.12906194e-01, -8.87927264e-02,\n",
       "       -5.32741487e-01,  3.77205074e-01,  1.32150184e-02,  1.67013928e-01,\n",
       "        1.78738255e-02,  5.00186145e-01, -5.42496800e-01, -4.89449233e-01,\n",
       "        4.09474876e-03, -9.54381526e-02, -3.49579990e-01,  2.41941214e-02,\n",
       "        2.81302631e-01,  1.05970733e-01, -1.30959705e-01,  1.58587977e-01,\n",
       "        4.41850781e-01,  4.92779054e-02, -1.72780171e-01,  4.53847289e-01,\n",
       "       -4.00546819e-01, -2.73611546e-01,  1.28668144e-01,  2.71967113e-01,\n",
       "        3.21254283e-01,  3.10803384e-01, -1.59290805e-01,  1.00946583e-01,\n",
       "       -3.85250188e-02, -1.99442938e-01, -2.69859135e-01,  5.77944756e-01,\n",
       "        2.70367116e-01,  4.32770044e-01,  5.39433837e-01,  4.71407145e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['night']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07672799,  0.00973572, -0.51288426,  0.4476877 ,  0.51063144,\n",
       "       -0.29056957, -0.16643377, -0.03358696,  0.36901104,  0.27614596,\n",
       "       -0.5546457 , -0.02012125, -0.58049345,  0.35754701,  0.2655268 ,\n",
       "       -0.04965462, -0.16471185,  0.17855662,  0.19501755, -0.32570162,\n",
       "       -0.20110163,  0.26402733, -0.34305644,  0.01563679, -0.7180861 ,\n",
       "        0.63717043,  0.11359484,  0.15489486,  0.35225046,  0.00689856,\n",
       "       -0.5569709 ,  0.221257  ,  0.07347611, -0.4380085 ,  0.39914072,\n",
       "        0.0980963 , -0.12754871, -0.06904901,  0.36826727,  0.20910455,\n",
       "       -0.00362907, -0.06345739,  0.34115458, -0.06107789,  0.10262474,\n",
       "        0.16722696, -0.12506145,  0.19204657, -0.02991424, -0.34114182,\n",
       "       -0.48763385, -0.47133043,  0.05262994,  0.00075857,  0.352133  ,\n",
       "       -0.6848708 , -0.09930194, -0.15151477,  0.01734567, -0.02622395,\n",
       "        0.17119884, -0.09591019, -0.44669098, -0.07795443, -0.4646708 ,\n",
       "        0.32806468,  0.01163389,  0.14541139,  0.01733191,  0.43663052,\n",
       "       -0.47269917, -0.42606986,  0.0035261 , -0.08404583, -0.30439144,\n",
       "        0.02028424,  0.24517757,  0.09254397, -0.11222308,  0.13739023,\n",
       "        0.3858194 ,  0.04277355, -0.15142529,  0.39463988, -0.3479729 ,\n",
       "       -0.2378007 ,  0.11416708,  0.2382666 ,  0.27924967,  0.27153337,\n",
       "       -0.13914385,  0.08770864, -0.03498157, -0.17352325, -0.23496167,\n",
       "        0.50388116,  0.23465532,  0.37569892,  0.4696833 ,  0.4110552 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['nights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999928"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"night\", \"nights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breakfast'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"breakfast cereal dinner lunch\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 0.23961403965950012),\n",
       " ('40', 0.23430491983890533),\n",
       " ('2', 0.23235931992530823),\n",
       " ('26', 0.23015664517879486),\n",
       " ('20', 0.23013760149478912),\n",
       " ('UN', 0.2299460470676422),\n",
       " ('blaze', 0.22948595881462097),\n",
       " ('keep', 0.22878581285476685),\n",
       " ('As', 0.2280689775943756),\n",
       " ('...', 0.22806063294410706)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['baghdad', 'england'], negative=['london'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
