{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datastructure.generator\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generator\n",
    "https://www.liaoxuefeng.com/wiki/1016959663602400/1017318207388128\n",
    "\n",
    "通过列表生成式，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。\n",
    "\n",
    "所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。\n",
    "\n",
    "## generator创建方式1\n",
    "要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = [x * x for x in range(10)]\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x10a774318>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = (x * x for x in range(10))\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建L和g的区别仅在于最外层的[]和()，L是一个list，而g是一个generator。\n",
    "\n",
    "我们可以直接打印出list的每一个元素，但我们怎么打印出generator的每一个元素呢？\n",
    "\n",
    "如果要一个一个打印出来，可以通过next()函数获得generator的下一个返回值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 16, 25, 36, 49, 64, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(g), next(g), next(g), next(g), next(g), next(g), next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e734f8aca5ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们讲过，generator保存的是算法，每次调用next(g)，就计算出g的下一个元素的值，直到计算到最后一个元素，没有更多的元素时，抛出StopIteration的错误。\n",
    "\n",
    "当然，上面这种不断调用next(g)实在是太变态了，正确的方法是使用for循环，因为generator也是可迭代对象："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "g = (x * x for x in range(3))\n",
    "for n in g:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。\n",
    "\n",
    "generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。\n",
    "\n",
    "比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到：\n",
    "\n",
    "1, 1, 2, 3, 5, 8, 13, 21, 34, ...\n",
    "\n",
    "斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(max):\n",
    "    n, a, b = 0, 0, 1\n",
    "    while n < max:\n",
    "        print(b)\n",
    "        a, b = b, a + b  # 注意，赋值语句相当于t = (b, a + b) # t是一个tuple; a = t[0]; b = t[1]\n",
    "        n = n + 1\n",
    "    return 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fib(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仔细观察，可以看出，fib函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似generator。\n",
    "## generator创建方式2: 函数\n",
    "带有yield的函数都被看成生成器，生成器是可迭代对象，且具备`__iter__` 和 `__next__`方法， 可以遍历获取元素\n",
    "python要求迭代器本身也是可迭代的，所以我们还要为迭代器实现`__iter__`方法，而`__iter__`方法要返回一个迭代器，迭代器自身正是一个迭代器，所以迭代器的`__iter__`方法返回自身即可\n",
    "\n",
    "也就是说，上面的函数和generator仅一步之遥。要把fib函数变成generator，只需要把print(b)改为yield b就可以了：\n",
    "\n",
    "这就是定义generator的另一种方法。如果一个函数定义中包含yield关键字，那么这个函数就不再是一个普通函数，而是一个generator：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib(max):\n",
    "    n, a, b = 0, 0, 1\n",
    "    while n < max:\n",
    "        yield b\n",
    "        a, b = b, a + b\n",
    "        n = n + 1\n",
    "    return 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object fib at 0x10a774228>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = fib(6)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，最难理解的就是generator和函数的执行流程不一样。函数是顺序执行，遇到return语句或者最后一行函数语句就返回。而变成generator的函数，在每次调用next()的时候执行，遇到yield语句返回，再次执行时从上次返回的yield语句处继续执行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(object):\n",
    "    \"\"\"\n",
    "    基类: 数据生成器模版, 子类需要实现__iter__()\n",
    "    https://github.com/bojone/bert4keras/blob/master/bert4keras/snippets.py\n",
    "    \"\"\"\n",
    "    def __init__(self, data, batch_size=32, buffer_size=None):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        if hasattr(self.data, '__len__'):\n",
    "            self.steps = len(self.data) // self.batch_size\n",
    "            if len(self.data) % self.batch_size != 0:\n",
    "                self.steps += 1\n",
    "        else:\n",
    "            self.steps = None\n",
    "        self.buffer_size = buffer_size or batch_size * 1000\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def sample(self, random=False):\n",
    "        \"\"\"\n",
    "        采样函数，每个样本同时返回一个is_end标记\n",
    "        :random: \n",
    "            False: 按顺序生成 数据\n",
    "            True: 先打乱 再生成数据\n",
    "        \"\"\"\n",
    "        if random:\n",
    "            if self.steps is None:\n",
    "\n",
    "                def generator():\n",
    "                    caches, isfull = [], False\n",
    "                    for d in self.data:\n",
    "                        caches.append(d)\n",
    "                        if isfull:\n",
    "                            i = np.random.randint(len(caches))\n",
    "                            yield caches.pop(i)\n",
    "                        elif len(caches) == self.buffer_size:\n",
    "                            isfull = True\n",
    "                    while caches:\n",
    "                        i = np.random.randint(len(caches))\n",
    "                        yield caches.pop(i)\n",
    "\n",
    "            else:\n",
    "\n",
    "                def generator():\n",
    "                    indices = list(range(len(self.data)))\n",
    "                    np.random.shuffle(indices)\n",
    "                    for i in indices:\n",
    "                        yield self.data[i]\n",
    "\n",
    "            data = generator()\n",
    "        else:\n",
    "            data = iter(self.data)\n",
    "\n",
    "        d_current = next(data)\n",
    "        for d_next in data:\n",
    "            yield False, d_current\n",
    "            d_current = d_next\n",
    "\n",
    "        yield True, d_current\n",
    "\n",
    "    def __iter__(self, random=False):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forfit(self):\n",
    "        while True:\n",
    "            for d in self.__iter__(True):\n",
    "                yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    \"\"\"\n",
    "    子类实例: 数据生成器\n",
    "    \n",
    "    return:\n",
    "    [\n",
    "        batch_token_ids, \n",
    "        batch_segment_ids,\n",
    "        batch_subject_labels, \n",
    "        batch_subject_ids,\n",
    "        batch_object_labels\n",
    "    ], None\n",
    "    \"\"\"\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids = [], []\n",
    "        batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n",
    "        for is_end, d in self.sample(random):\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                d['text'], max_length=maxlen\n",
    "            )\n",
    "            # 整理三元组 {s: [(o, p)]}\n",
    "            spoes = {}\n",
    "            for s, p, o in d['spo_list']:\n",
    "                s = tokenizer.encode(s)[0][1:-1]\n",
    "                p = predicate2id[p]\n",
    "                o = tokenizer.encode(o)[0][1:-1]\n",
    "                s_idx = search(s, token_ids)\n",
    "                o_idx = search(o, token_ids)\n",
    "                if s_idx != -1 and o_idx != -1:\n",
    "                    s = (s_idx, s_idx + len(s) - 1)\n",
    "                    o = (o_idx, o_idx + len(o) - 1, p)\n",
    "                    if s not in spoes:\n",
    "                        spoes[s] = []\n",
    "                    spoes[s].append(o)\n",
    "            if spoes:\n",
    "                # subject标签\n",
    "                subject_labels = np.zeros((len(token_ids), 2))\n",
    "                for s in spoes:\n",
    "                    subject_labels[s[0], 0] = 1\n",
    "                    subject_labels[s[1], 1] = 1\n",
    "                # 随机选一个subject \n",
    "                # mayi: 这里随机选取subject的方法很奇特，同时生成了负样本，如选到的subject_ids不存在时，object_labels都为0\n",
    "                start, end = np.array(list(spoes.keys())).T\n",
    "                start = np.random.choice(start)\n",
    "                end = np.random.choice(end[end >= start])\n",
    "                # subject对应的索引位置\n",
    "                subject_ids = (start, end)\n",
    "                # 对应的object标签\n",
    "                object_labels = np.zeros((len(token_ids), len(predicate2id), 2))\n",
    "                for o in spoes.get(subject_ids, []):\n",
    "                    object_labels[o[0], o[2], 0] = 1\n",
    "                    object_labels[o[1], o[2], 1] = 1\n",
    "                # 构建batch\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "                batch_subject_labels.append(subject_labels)\n",
    "                batch_subject_ids.append(subject_ids)\n",
    "                batch_object_labels.append(object_labels)\n",
    "                if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                    batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                    batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                    batch_subject_labels = sequence_padding(\n",
    "                        batch_subject_labels, padding=np.zeros(2)\n",
    "                    )\n",
    "                    batch_subject_ids = np.array(batch_subject_ids)\n",
    "                    batch_object_labels = sequence_padding(\n",
    "                        batch_object_labels,\n",
    "                        padding=np.zeros((len(predicate2id), 2))\n",
    "                    )\n",
    "                    yield [\n",
    "                        batch_token_ids, batch_segment_ids,\n",
    "                        batch_subject_labels, batch_subject_ids,\n",
    "                        batch_object_labels\n",
    "                    ], None\n",
    "                    batch_token_ids, batch_segment_ids = [], []\n",
    "                    batch_subject_labels, batch_subject_ids, batch_object_labels = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00_template.ipynb.\n",
      "Converted active_learning.ipynb.\n",
      "Converted algo_dl_keras.ipynb.\n",
      "Converted algo_ml_eda.ipynb.\n",
      "Converted algo_ml_tree_catboost.ipynb.\n",
      "Converted algo_ml_tree_lgb.ipynb.\n",
      "Converted algo_rs_associated_rules.ipynb.\n",
      "Converted algo_rs_match_deepmatch.ipynb.\n",
      "Converted algo_rs_matrix.ipynb.\n",
      "Converted algo_rs_search_vector_faiss.ipynb.\n",
      "Converted algo_seq_embeding.ipynb.\n",
      "Converted algo_seq_features_extraction_text.ipynb.\n",
      "Converted datastructure_dict_list_set.ipynb.\n",
      "Converted datastructure_matrix_sparse.ipynb.\n",
      "Converted engineering_concurrency.ipynb.\n",
      "Converted engineering_nbdev.ipynb.\n",
      "Converted engineering_panel.ipynb.\n",
      "Converted engineering_snorkel.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted math_func_basic.ipynb.\n",
      "Converted math_func_loss.ipynb.\n",
      "Converted operating_system_command.ipynb.\n",
      "Converted plot.ipynb.\n",
      "Converted utils_functools.ipynb.\n",
      "Converted utils_json.ipynb.\n",
      "Converted utils_pickle.ipynb.\n",
      "Converted utils_time.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No notebooks were modified\r\n",
      "converting /Users/luoyonggui/PycharmProjects/nbdevlib/index.ipynb to README.md\r\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
