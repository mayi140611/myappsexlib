{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp algo.ml.model_fusion\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# algo-ml-model_fusion\n",
    "https://www.bilibili.com/video/BV13K4y1k7Vy?from=search&seid=1387898537183725066\n",
    "\n",
    "![](img/fuse01.png)\n",
    "# 基本原理\n",
    "## 偏差-方差\n",
    "https://www.cnblogs.com/hutao722/p/9921788.html\n",
    "\n",
    "集成学习是一种组合类型的学习方法。它采用多个基分类器组合成一个总分类器，能够达到单个基分类器所达不到的效果。根据将多个基分类器集成在一起的方式，集成学习主要分为两类：\n",
    "\n",
    "平均方法：例如随机森林， Bagging methods。在平均方法中，系统分别去建立多个基分类器，分类器之间没有任何联系。然后在分类或者回归阶段，各个分类器根据测试数据给出自己的答案，然后系统根据各个分类器给出的结果去综合出最后的结果，比如可以使投票的形式。\n",
    "\n",
    "提升方法：例如梯度提升决策树GBDT，AdaBoost。在提升方法中，系统模型在训练过程中会先后建立一系列分类器，这些分类器单个可能是弱分类器，但是组合起来就成为一个强分类器。\n",
    "\n",
    "__平均方法通常比其任何一个基分类器效果好因为尝试去降低模型的方差，而提升方法尝试去降低模型的偏差。__\n",
    "\n",
    "### 方差和偏差的来源\n",
    "https://blog.csdn.net/njustzj001/article/details/47314927  \n",
    "我们机器学习的模型，必不可少地对数据非常依赖。然而，如果你不知道数据服从一个什么样的分布，或者你没有办法拿到所有可能的数据（肯定拿不到所有的），那么我们训练出来的模型和真实模型之间，就会存在不一致。这种不一致表现在两个方面。\n",
    "\n",
    "真实模型根本就没有包含在我们训练模型的模型空间中。比如本来是非线性模型，你非要拿线性模型去拟合数据，那么不论你怎么调整模型参数去选择模型，结果也是不对的。这就是偏差的来源。表现为模型不正确。\n",
    "不管真实模型在不在我们训练模型的空间中，由于我们不能拿到所有可能的数据，如果拿到的数据不是那么具有代表性，那么不同的数据训练出来的模型参数就会不同。然后用这个模型去做预测，结果也就会和真实值之间有差异。这就是方差的来源。表现为模型不稳定。\n",
    "\n",
    "这里注意的是，简单模型由于偏差较大，不宜作为结果直接融合，因为这样会把偏差较小的模型的结果也带偏！\n",
    "![](img/fuse02.png)\n",
    "![](img/fuse03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/bias01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 举例\n",
    "通过观察train set error，可以了解数据拟合情况，可以判断数据是否有偏差问题\n",
    "\n",
    "通过观察val set error，可以判断数据方差是否过高\n",
    "\n",
    "以下的基本假设:  \n",
    "* 基本误差(human)接近0%，\n",
    "* 训练集和测试集来自相同分布\n",
    "\n",
    "#### high Variance\n",
    "train set error: 1%\n",
    "\n",
    "val set error: 11%\n",
    "\n",
    "overfitting 就说明模型具有高方差 high Variance。\n",
    "\n",
    "#### high bias\n",
    "train set error: 15%\n",
    "\n",
    "val set error: 16%\n",
    "underfitting 就说明模型具有高偏差 high bias。\n",
    "#### high Variance & high bias\n",
    "train set error: 15%\n",
    "\n",
    "val set error: 30%\n",
    "#### low Variance & low bias\n",
    "train set error: 0.5%\n",
    "\n",
    "val set error: 1%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "Bagging的思想是利用抽样生成不同的训练集，进而训练不同的模型，将这些模型的输出结果综合（投票或平均的方式）得到最终的结果。Bagging本质上是利用了模型的多样性，改善算法整体的效果。\n",
    "\n",
    "Bagging的重点在于不同训练集的生成，这里使用了一种名为Bootstrap的方法，即有放回的重复随机抽样，从而生成不同的数据集。\n",
    "![](img/fuse04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## boosting\n",
    "![](img/fuse05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 平均融合 | 加权融合\n",
    "平均融合: 把多个模型的结果相加取平均 作为最后的结果\n",
    "\n",
    "加权融合: 把多个模型的结果 以各自线下验证集的得分作为权重 加权融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting\n",
    "![](img/fuse06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blending\n",
    "将数据划分为训练集和测试集(test_set)，其中训练集需要再次划分为训练集(train_set)和验证集(val_set)；\n",
    "\n",
    "然后用训练集训练多个模型，用验证集判断检验模型，确定模型参数。\n",
    "\n",
    "然后用训练集训练的n个模型，对验证集进行验证，得到n个结果集，\n",
    "\n",
    "再把这n个结果集作为n个特征和原来的特征合并到一起，用val_set再训练一个模型\n",
    "![](img/fuse07.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stacking\n",
    "![](img/fuse08.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending与Stacking对比\n",
    "\n",
    "Blending的优点在于：\n",
    "\n",
    "1.比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）\n",
    "\n",
    "2.避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集\n",
    "\n",
    "3.在团队建模过程中，不需要给队友分享自己的随机种子\n",
    "\n",
    "而缺点在于：\n",
    "\n",
    "1.使用了很少的数据（是划分hold-out作为测试集，并非cv）\n",
    "\n",
    "2.blender可能会过拟合（其实大概率是第一点导致的）\n",
    "\n",
    "3.stacking使用多次的CV会比较稳健"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00_template.ipynb.\n",
      "Converted active_learning.ipynb.\n",
      "Converted algo_dl_keras.ipynb.\n",
      "Converted algo_dl_loss.ipynb.\n",
      "Converted algo_dl_optimizers.ipynb.\n",
      "Converted algo_dl_pytorch.ipynb.\n",
      "Converted algo_ml_tree_catboost.ipynb.\n",
      "Converted algo_ml_tree_lgb.ipynb.\n",
      "Converted algo_rs_match_associated_rules.ipynb.\n",
      "Converted algo_rs_match_deepmatch.ipynb.\n",
      "Converted algo_rs_match_matrix.ipynb.\n",
      "Converted algo_rs_search_vector_faiss.ipynb.\n",
      "Converted algo_seq_embeding.ipynb.\n",
      "Converted algo_seq_embeding_glove.ipynb.\n",
      "Converted algo_seq_features_extraction_text.ipynb.\n",
      "Converted data-processing-eda.ipynb.\n",
      "Converted data-processing-tf_data.ipynb.\n",
      "Converted data_processing_split.ipynb.\n",
      "Converted datastructure_dict_list_set.ipynb.\n",
      "Converted datastructure_generator.ipynb.\n",
      "Converted datastructure_matrix_sparse.ipynb.\n",
      "Converted engineering-colab-kagglelab.ipynb.\n",
      "Converted engineering_concurrency.ipynb.\n",
      "Converted engineering_docker.ipynb.\n",
      "Converted engineering_gc.ipynb.\n",
      "Converted engineering_nbdev.ipynb.\n",
      "Converted engineering_panel.ipynb.\n",
      "Converted engineering_snorkel.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted math_func_basic.ipynb.\n",
      "Converted operating_system_command.ipynb.\n",
      "Converted plot.ipynb.\n",
      "Converted utils_functools.ipynb.\n",
      "Converted utils_json.ipynb.\n",
      "Converted utils_pickle.ipynb.\n",
      "Converted utils_time.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No notebooks were modified\r\n",
      "converting /Users/luoyonggui/PycharmProjects/nbdevlib/index.ipynb to README.md\r\n"
     ]
    }
   ],
   "source": [
    "!nbdev_build_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
