{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 思路\n",
    "有user_df和没有user_df分别训练一个nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepmatch==0.1.3\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U deepmatch\n",
    "!pip freeze | grep deepmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deepctr.inputs import SparseFeat, VarLenSparseFeat\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gen_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_set(data, negsample: int=0):\n",
    "    \"\"\"\n",
    "    negsample: 负样本数相对于正样本数的倍数\n",
    "    \"\"\"\n",
    "    data.sort_values(\"time\", inplace=True)\n",
    "    item_ids = data['item_id'].unique()\n",
    "\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for reviewerID, hist in tqdm(data.groupby('user_id')):\n",
    "        pos_list = hist['item_id'].tolist()  # 用户看过的电影列表\n",
    "#         rating_list = hist['rating'].tolist()  # 用户看过的电影评分列表\n",
    "\n",
    "        if negsample > 0:\n",
    "            # 产生负样本，策略：从用户没有评分的items中随机有放回采样\n",
    "            candidate_set = list(set(item_ids) - set(pos_list))\n",
    "            neg_list = np.random.choice(candidate_set,size=len(pos_list)*negsample,replace=True)\n",
    "        for i in range(1, len(pos_list)):\n",
    "            hist = pos_list[:i]\n",
    "            if i != len(pos_list) - 1:\n",
    "                # (user_id, items_list, next_item, label, items_list_length, next_item_rating)\n",
    "                train_set.append((reviewerID, hist[::-1], pos_list[i], 1,len(hist[::-1]),item_profile.loc[hist[-1]].values.tolist()))\n",
    "                for negi in range(negsample):\n",
    "                    train_set.append((reviewerID, hist[::-1], neg_list[i*negsample+negi], 0,len(hist[::-1]),item_profile.loc[hist[-1]].values.tolist()))\n",
    "            else:\n",
    "                test_set.append((reviewerID, hist[::-1], pos_list[i],1,len(hist[::-1]),item_profile.loc[hist[-1]].values.tolist()))\n",
    "\n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "\n",
    "    print(len(train_set[0]),len(test_set[0]))\n",
    "\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gen_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_input(train_set,user_profile,seq_max_len):\n",
    "\n",
    "    train_uid = np.array([line[0] for line in train_set])\n",
    "    train_seq = [line[1] for line in train_set]\n",
    "    train_iid = np.array([line[2] for line in train_set])\n",
    "    train_label = np.array([line[3] for line in train_set])\n",
    "    train_hist_len = np.array([line[4] for line in train_set])\n",
    "    item_feat_last = np.array([line[5] for line in train_set])\n",
    "\n",
    "    train_seq_pad = pad_sequences(train_seq, maxlen=seq_max_len, padding='post', truncating='post', value=0)\n",
    "    train_model_input = {\"user_id\": train_uid, \"item_id\": train_iid, \"hist_item_id\": train_seq_pad,\n",
    "                         \"hist_len\": train_hist_len, 'item_feat_last': item_feat_last}\n",
    "\n",
    "    for key in [\"user_gender\", \"user_age_level\", \"user_city_level\"]:\n",
    "        train_model_input[key] = user_profile.loc[train_model_input['user_id']][key].values\n",
    "\n",
    "    return train_model_input,train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.eda import * \n",
    "from code.config import args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-21 20:15:46.674 | INFO     | code.eda:load_whole_click_data:54 - phase: 0\n",
      "2020-05-21 20:15:47.099 | INFO     | code.eda:load_whole_click_data:54 - phase: 1\n",
      "2020-05-21 20:15:47.532 | INFO     | code.eda:load_whole_click_data:54 - phase: 2\n",
      "2020-05-21 20:15:47.997 | INFO     | code.eda:load_whole_click_data:54 - phase: 3\n",
      "2020-05-21 20:15:48.540 | INFO     | code.eda:load_whole_click_data:54 - phase: 4\n",
      "2020-05-21 20:15:49.099 | INFO     | code.eda:load_whole_click_data:54 - phase: 5\n",
      "2020-05-21 20:15:49.690 | INFO     | code.eda:load_whole_click_data:54 - phase: 6\n",
      "2020-05-21 20:15:59.886 | INFO     | code.eda:load_whole_click_data:84 - whole_click_train: (954588, 4), whole_click_val: (12081, 4), click_test: (175274, 4), test_qtime: (12081, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(966669, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "whole_click_train, whole_click_val, click_test, test_qtime = load_whole_click_data(args.now_phase, args.DATA_DIR)\n",
    "\n",
    "# 完整的click数据\n",
    "whole_click = whole_click_train.append(whole_click_val)\n",
    "\n",
    "whole_click.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = get_user_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/PycharmProjects/myappsexlib/a_0330_0527_Modern_E_Commerce_Platform_Debiasing/code/eda.py:32: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  converters={'item_id':str})\n"
     ]
    }
   ],
   "source": [
    "item_df = get_item_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'user_age_level', 'user_gender', 'user_city_level'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(pd.merge(whole_click, user_df), item_df, how='left')\n",
    "# data = pd.merge(pd.merge(click_test.iloc[:10000], user_df, how='left'), item_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255162, 263)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 255162 entries, 0 to 255161\n",
      "Columns: 263 entries, user_id to 255\n",
      "dtypes: float64(256), int64(1), object(6)\n",
      "memory usage: 513.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>phase</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_city_level</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12136</td>\n",
       "      <td>28195</td>\n",
       "      <td>0.9837396808253338</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>4.158704</td>\n",
       "      <td>-2.213841</td>\n",
       "      <td>3.299623</td>\n",
       "      <td>-3.816672</td>\n",
       "      <td>1.817951</td>\n",
       "      <td>-0.562453</td>\n",
       "      <td>-3.637601</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-5.418423</td>\n",
       "      <td>-2.103671</td>\n",
       "      <td>-0.442526</td>\n",
       "      <td>-3.839618</td>\n",
       "      <td>4.380653</td>\n",
       "      <td>-3.727894</td>\n",
       "      <td>1.042084</td>\n",
       "      <td>-2.424195</td>\n",
       "      <td>3.287570</td>\n",
       "      <td>-0.606853</td>\n",
       "      <td>-1.033391</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>-0.038618</td>\n",
       "      <td>-1.071147</td>\n",
       "      <td>0.780368</td>\n",
       "      <td>-0.15989</td>\n",
       "      <td>-1.548846</td>\n",
       "      <td>-2.328499</td>\n",
       "      <td>-0.205781</td>\n",
       "      <td>-3.355978</td>\n",
       "      <td>-5.415924</td>\n",
       "      <td>-1.503188</td>\n",
       "      <td>-5.305884</td>\n",
       "      <td>-1.843716</td>\n",
       "      <td>-0.245827</td>\n",
       "      <td>3.008088</td>\n",
       "      <td>3.399326</td>\n",
       "      <td>-3.194445</td>\n",
       "      <td>-3.39710</td>\n",
       "      <td>-0.312699</td>\n",
       "      <td>2.398918</td>\n",
       "      <td>4.553303</td>\n",
       "      <td>-2.690272</td>\n",
       "      <td>1.037717</td>\n",
       "      <td>1.235074</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572505</td>\n",
       "      <td>-1.981386</td>\n",
       "      <td>-1.908951</td>\n",
       "      <td>3.034426</td>\n",
       "      <td>-4.374824</td>\n",
       "      <td>0.489178</td>\n",
       "      <td>-3.051432</td>\n",
       "      <td>-2.832758</td>\n",
       "      <td>-2.986957</td>\n",
       "      <td>-1.558040</td>\n",
       "      <td>4.542650</td>\n",
       "      <td>-0.078699</td>\n",
       "      <td>2.846123</td>\n",
       "      <td>2.866818</td>\n",
       "      <td>-2.151008</td>\n",
       "      <td>0.465624</td>\n",
       "      <td>3.206414</td>\n",
       "      <td>-2.886617</td>\n",
       "      <td>-0.973224</td>\n",
       "      <td>4.858570</td>\n",
       "      <td>0.401090</td>\n",
       "      <td>1.429223</td>\n",
       "      <td>-1.306388</td>\n",
       "      <td>2.436626</td>\n",
       "      <td>0.375304</td>\n",
       "      <td>0.796462</td>\n",
       "      <td>-1.397474</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>-4.959344</td>\n",
       "      <td>-0.943585</td>\n",
       "      <td>0.348210</td>\n",
       "      <td>-2.54955</td>\n",
       "      <td>1.375585</td>\n",
       "      <td>-3.331098</td>\n",
       "      <td>0.260209</td>\n",
       "      <td>-1.60476</td>\n",
       "      <td>4.503458</td>\n",
       "      <td>0.519022</td>\n",
       "      <td>2.495067</td>\n",
       "      <td>-2.482817</td>\n",
       "      <td>-2.561544</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.523985</td>\n",
       "      <td>1.464158</td>\n",
       "      <td>0.655260</td>\n",
       "      <td>-0.055013</td>\n",
       "      <td>0.743994</td>\n",
       "      <td>2.011905</td>\n",
       "      <td>0.713488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12136</td>\n",
       "      <td>8180</td>\n",
       "      <td>0.9837398562121692</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>1.256375</td>\n",
       "      <td>-0.135355</td>\n",
       "      <td>-0.094411</td>\n",
       "      <td>-2.881465</td>\n",
       "      <td>-2.859680</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>-2.651040</td>\n",
       "      <td>-0.448493</td>\n",
       "      <td>-4.705667</td>\n",
       "      <td>-2.737536</td>\n",
       "      <td>-2.651793</td>\n",
       "      <td>-1.025328</td>\n",
       "      <td>3.507258</td>\n",
       "      <td>-0.903140</td>\n",
       "      <td>-0.954022</td>\n",
       "      <td>-0.176986</td>\n",
       "      <td>-0.129408</td>\n",
       "      <td>-0.903812</td>\n",
       "      <td>-1.485689</td>\n",
       "      <td>-1.232078</td>\n",
       "      <td>1.635235</td>\n",
       "      <td>0.191120</td>\n",
       "      <td>2.317544</td>\n",
       "      <td>-0.78316</td>\n",
       "      <td>-0.922034</td>\n",
       "      <td>-0.601006</td>\n",
       "      <td>1.982776</td>\n",
       "      <td>0.541685</td>\n",
       "      <td>-0.317295</td>\n",
       "      <td>1.846201</td>\n",
       "      <td>0.336760</td>\n",
       "      <td>-1.875458</td>\n",
       "      <td>1.001356</td>\n",
       "      <td>-2.466253</td>\n",
       "      <td>1.808531</td>\n",
       "      <td>-1.687020</td>\n",
       "      <td>1.17516</td>\n",
       "      <td>-2.430258</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>3.409604</td>\n",
       "      <td>-2.234955</td>\n",
       "      <td>1.543343</td>\n",
       "      <td>-0.720782</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292294</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>1.512545</td>\n",
       "      <td>-2.500110</td>\n",
       "      <td>-0.781102</td>\n",
       "      <td>-4.062862</td>\n",
       "      <td>-2.441689</td>\n",
       "      <td>1.630657</td>\n",
       "      <td>1.479393</td>\n",
       "      <td>-2.077727</td>\n",
       "      <td>2.233886</td>\n",
       "      <td>-1.078675</td>\n",
       "      <td>0.713491</td>\n",
       "      <td>-0.945299</td>\n",
       "      <td>-0.759625</td>\n",
       "      <td>0.223324</td>\n",
       "      <td>3.597754</td>\n",
       "      <td>-1.059106</td>\n",
       "      <td>1.967239</td>\n",
       "      <td>3.818967</td>\n",
       "      <td>1.521663</td>\n",
       "      <td>-1.366154</td>\n",
       "      <td>1.490747</td>\n",
       "      <td>1.029143</td>\n",
       "      <td>1.499049</td>\n",
       "      <td>-0.089437</td>\n",
       "      <td>-1.194861</td>\n",
       "      <td>0.879334</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>-0.082374</td>\n",
       "      <td>-3.172344</td>\n",
       "      <td>-2.91691</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>3.820774</td>\n",
       "      <td>-1.552581</td>\n",
       "      <td>-3.47731</td>\n",
       "      <td>-1.286526</td>\n",
       "      <td>-1.216785</td>\n",
       "      <td>-0.149395</td>\n",
       "      <td>-1.064123</td>\n",
       "      <td>1.278076</td>\n",
       "      <td>1.322566</td>\n",
       "      <td>-2.070811</td>\n",
       "      <td>-2.692464</td>\n",
       "      <td>-2.537409</td>\n",
       "      <td>-2.680542</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>2.710567</td>\n",
       "      <td>2.210895</td>\n",
       "      <td>-2.694886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id item_id                time  phase user_age_level user_gender user_city_level         0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22       23        24        25        26        27        28        29        30        31        32        33        34        35       36        37        38        39        40        41        42  ...       206       207       208       209       210       211       212       213       214       215       216       217       218       219       220       221       222       223       224       225       226       227       228       229       230       231       232       233       234       235       236      237       238       239       240      241       242       243       244       245       246       247       248       249       250       251       252       253       254       255\n",
       "0   12136   28195  0.9837396808253338      0              7           F               4  4.158704 -2.213841  3.299623 -3.816672  1.817951 -0.562453 -3.637601 -0.311089 -5.418423 -2.103671 -0.442526 -3.839618  4.380653 -3.727894  1.042084 -2.424195  3.287570 -0.606853 -1.033391  0.160277 -0.038618 -1.071147  0.780368 -0.15989 -1.548846 -2.328499 -0.205781 -3.355978 -5.415924 -1.503188 -5.305884 -1.843716 -0.245827  3.008088  3.399326 -3.194445 -3.39710 -0.312699  2.398918  4.553303 -2.690272  1.037717  1.235074  ... -1.572505 -1.981386 -1.908951  3.034426 -4.374824  0.489178 -3.051432 -2.832758 -2.986957 -1.558040  4.542650 -0.078699  2.846123  2.866818 -2.151008  0.465624  3.206414 -2.886617 -0.973224  4.858570  0.401090  1.429223 -1.306388  2.436626  0.375304  0.796462 -1.397474  0.019915 -4.959344 -0.943585  0.348210 -2.54955  1.375585 -3.331098  0.260209 -1.60476  4.503458  0.519022  2.495067 -2.482817 -2.561544 -0.005109 -0.008450 -0.523985  1.464158  0.655260 -0.055013  0.743994  2.011905  0.713488\n",
       "1   12136    8180  0.9837398562121692      0              7           F               4  1.256375 -0.135355 -0.094411 -2.881465 -2.859680  0.219944 -2.651040 -0.448493 -4.705667 -2.737536 -2.651793 -1.025328  3.507258 -0.903140 -0.954022 -0.176986 -0.129408 -0.903812 -1.485689 -1.232078  1.635235  0.191120  2.317544 -0.78316 -0.922034 -0.601006  1.982776  0.541685 -0.317295  1.846201  0.336760 -1.875458  1.001356 -2.466253  1.808531 -1.687020  1.17516 -2.430258  0.835395  3.409604 -2.234955  1.543343 -0.720782  ...  2.292294  0.804790  1.512545 -2.500110 -0.781102 -4.062862 -2.441689  1.630657  1.479393 -2.077727  2.233886 -1.078675  0.713491 -0.945299 -0.759625  0.223324  3.597754 -1.059106  1.967239  3.818967  1.521663 -1.366154  1.490747  1.029143  1.499049 -0.089437 -1.194861  0.879334  0.018344 -0.082374 -3.172344 -2.91691  0.775857  3.820774 -1.552581 -3.47731 -1.286526 -1.216785 -0.149395 -1.064123  1.278076  1.322566 -2.070811 -2.692464 -2.537409 -2.680542  0.139775  2.710567  2.210895 -2.694886\n",
       "\n",
       "[2 rows x 263 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 50\n",
    "negsample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [\"item_id\", \"user_id\",\n",
    "                    \"user_gender\", \"user_age_level\", \"user_city_level\"]\n",
    "\n",
    "\n",
    "# 1.Label Encoding for sparse features,and process sequence features with `gen_date_set` and `gen_model_input`\n",
    "\n",
    "features = sparse_features\n",
    "feature_max_idx = {}\n",
    "lbe_dict = {}\n",
    "for feature in features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature] = lbe.fit_transform(data[feature]) + 1\n",
    "    feature_max_idx[feature] = data[feature].max() + 1\n",
    "    lbe_dict[feature] = lbe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = data[[\"user_id\",\n",
    "                    \"user_gender\", \"user_age_level\", \"user_city_level\"]].drop_duplicates('user_id')\n",
    "\n",
    "item_profile = data[[\"item_id\"]+list(range(256))].drop_duplicates('item_id')\n",
    "\n",
    "user_profile.set_index(\"user_id\", inplace=True)\n",
    "item_profile.set_index(\"item_id\", inplace=True)\n",
    "\n",
    "user_item_list = data.groupby(\"user_id\")['item_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26220</th>\n",
       "      <td>4.158704</td>\n",
       "      <td>-2.213841</td>\n",
       "      <td>3.299623</td>\n",
       "      <td>-3.816672</td>\n",
       "      <td>1.817951</td>\n",
       "      <td>-0.562453</td>\n",
       "      <td>-3.637601</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-5.418423</td>\n",
       "      <td>-2.103671</td>\n",
       "      <td>-0.442526</td>\n",
       "      <td>-3.839618</td>\n",
       "      <td>4.380653</td>\n",
       "      <td>-3.727894</td>\n",
       "      <td>1.042084</td>\n",
       "      <td>-2.424195</td>\n",
       "      <td>3.287570</td>\n",
       "      <td>-0.606853</td>\n",
       "      <td>-1.033391</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>-0.038618</td>\n",
       "      <td>-1.071147</td>\n",
       "      <td>0.780368</td>\n",
       "      <td>-0.15989</td>\n",
       "      <td>-1.548846</td>\n",
       "      <td>-2.328499</td>\n",
       "      <td>-0.205781</td>\n",
       "      <td>-3.355978</td>\n",
       "      <td>-5.415924</td>\n",
       "      <td>-1.503188</td>\n",
       "      <td>-5.305884</td>\n",
       "      <td>-1.843716</td>\n",
       "      <td>-0.245827</td>\n",
       "      <td>3.008088</td>\n",
       "      <td>3.399326</td>\n",
       "      <td>-3.194445</td>\n",
       "      <td>-3.39710</td>\n",
       "      <td>-0.312699</td>\n",
       "      <td>2.398918</td>\n",
       "      <td>4.553303</td>\n",
       "      <td>-2.690272</td>\n",
       "      <td>1.037717</td>\n",
       "      <td>1.235074</td>\n",
       "      <td>4.735878</td>\n",
       "      <td>1.678928</td>\n",
       "      <td>-1.881256</td>\n",
       "      <td>0.291053</td>\n",
       "      <td>1.781230</td>\n",
       "      <td>1.398565</td>\n",
       "      <td>3.934110</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572505</td>\n",
       "      <td>-1.981386</td>\n",
       "      <td>-1.908951</td>\n",
       "      <td>3.034426</td>\n",
       "      <td>-4.374824</td>\n",
       "      <td>0.489178</td>\n",
       "      <td>-3.051432</td>\n",
       "      <td>-2.832758</td>\n",
       "      <td>-2.986957</td>\n",
       "      <td>-1.558040</td>\n",
       "      <td>4.542650</td>\n",
       "      <td>-0.078699</td>\n",
       "      <td>2.846123</td>\n",
       "      <td>2.866818</td>\n",
       "      <td>-2.151008</td>\n",
       "      <td>0.465624</td>\n",
       "      <td>3.206414</td>\n",
       "      <td>-2.886617</td>\n",
       "      <td>-0.973224</td>\n",
       "      <td>4.858570</td>\n",
       "      <td>0.401090</td>\n",
       "      <td>1.429223</td>\n",
       "      <td>-1.306388</td>\n",
       "      <td>2.436626</td>\n",
       "      <td>0.375304</td>\n",
       "      <td>0.796462</td>\n",
       "      <td>-1.397474</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>-4.959344</td>\n",
       "      <td>-0.943585</td>\n",
       "      <td>0.348210</td>\n",
       "      <td>-2.54955</td>\n",
       "      <td>1.375585</td>\n",
       "      <td>-3.331098</td>\n",
       "      <td>0.260209</td>\n",
       "      <td>-1.60476</td>\n",
       "      <td>4.503458</td>\n",
       "      <td>0.519022</td>\n",
       "      <td>2.495067</td>\n",
       "      <td>-2.482817</td>\n",
       "      <td>-2.561544</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.523985</td>\n",
       "      <td>1.464158</td>\n",
       "      <td>0.655260</td>\n",
       "      <td>-0.055013</td>\n",
       "      <td>0.743994</td>\n",
       "      <td>2.011905</td>\n",
       "      <td>0.713488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67762</th>\n",
       "      <td>1.256375</td>\n",
       "      <td>-0.135355</td>\n",
       "      <td>-0.094411</td>\n",
       "      <td>-2.881465</td>\n",
       "      <td>-2.859680</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>-2.651040</td>\n",
       "      <td>-0.448493</td>\n",
       "      <td>-4.705667</td>\n",
       "      <td>-2.737536</td>\n",
       "      <td>-2.651793</td>\n",
       "      <td>-1.025328</td>\n",
       "      <td>3.507258</td>\n",
       "      <td>-0.903140</td>\n",
       "      <td>-0.954022</td>\n",
       "      <td>-0.176986</td>\n",
       "      <td>-0.129408</td>\n",
       "      <td>-0.903812</td>\n",
       "      <td>-1.485689</td>\n",
       "      <td>-1.232078</td>\n",
       "      <td>1.635235</td>\n",
       "      <td>0.191120</td>\n",
       "      <td>2.317544</td>\n",
       "      <td>-0.78316</td>\n",
       "      <td>-0.922034</td>\n",
       "      <td>-0.601006</td>\n",
       "      <td>1.982776</td>\n",
       "      <td>0.541685</td>\n",
       "      <td>-0.317295</td>\n",
       "      <td>1.846201</td>\n",
       "      <td>0.336760</td>\n",
       "      <td>-1.875458</td>\n",
       "      <td>1.001356</td>\n",
       "      <td>-2.466253</td>\n",
       "      <td>1.808531</td>\n",
       "      <td>-1.687020</td>\n",
       "      <td>1.17516</td>\n",
       "      <td>-2.430258</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>3.409604</td>\n",
       "      <td>-2.234955</td>\n",
       "      <td>1.543343</td>\n",
       "      <td>-0.720782</td>\n",
       "      <td>4.805836</td>\n",
       "      <td>-0.952767</td>\n",
       "      <td>-3.785604</td>\n",
       "      <td>2.363004</td>\n",
       "      <td>0.964829</td>\n",
       "      <td>1.373647</td>\n",
       "      <td>-1.082907</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292294</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>1.512545</td>\n",
       "      <td>-2.500110</td>\n",
       "      <td>-0.781102</td>\n",
       "      <td>-4.062862</td>\n",
       "      <td>-2.441689</td>\n",
       "      <td>1.630657</td>\n",
       "      <td>1.479393</td>\n",
       "      <td>-2.077727</td>\n",
       "      <td>2.233886</td>\n",
       "      <td>-1.078675</td>\n",
       "      <td>0.713491</td>\n",
       "      <td>-0.945299</td>\n",
       "      <td>-0.759625</td>\n",
       "      <td>0.223324</td>\n",
       "      <td>3.597754</td>\n",
       "      <td>-1.059106</td>\n",
       "      <td>1.967239</td>\n",
       "      <td>3.818967</td>\n",
       "      <td>1.521663</td>\n",
       "      <td>-1.366154</td>\n",
       "      <td>1.490747</td>\n",
       "      <td>1.029143</td>\n",
       "      <td>1.499049</td>\n",
       "      <td>-0.089437</td>\n",
       "      <td>-1.194861</td>\n",
       "      <td>0.879334</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>-0.082374</td>\n",
       "      <td>-3.172344</td>\n",
       "      <td>-2.91691</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>3.820774</td>\n",
       "      <td>-1.552581</td>\n",
       "      <td>-3.47731</td>\n",
       "      <td>-1.286526</td>\n",
       "      <td>-1.216785</td>\n",
       "      <td>-0.149395</td>\n",
       "      <td>-1.064123</td>\n",
       "      <td>1.278076</td>\n",
       "      <td>1.322566</td>\n",
       "      <td>-2.070811</td>\n",
       "      <td>-2.692464</td>\n",
       "      <td>-2.537409</td>\n",
       "      <td>-2.680542</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>2.710567</td>\n",
       "      <td>2.210895</td>\n",
       "      <td>-2.694886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22       23        24        25        26        27        28        29        30        31        32        33        34        35       36        37        38        39        40        41        42        43        44        45        46        47        48        49   ...       206       207       208       209       210       211       212       213       214       215       216       217       218       219       220       221       222       223       224       225       226       227       228       229       230       231       232       233       234       235       236      237       238       239       240      241       242       243       244       245       246       247       248       249       250       251       252       253       254       255\n",
       "item_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "26220    4.158704 -2.213841  3.299623 -3.816672  1.817951 -0.562453 -3.637601 -0.311089 -5.418423 -2.103671 -0.442526 -3.839618  4.380653 -3.727894  1.042084 -2.424195  3.287570 -0.606853 -1.033391  0.160277 -0.038618 -1.071147  0.780368 -0.15989 -1.548846 -2.328499 -0.205781 -3.355978 -5.415924 -1.503188 -5.305884 -1.843716 -0.245827  3.008088  3.399326 -3.194445 -3.39710 -0.312699  2.398918  4.553303 -2.690272  1.037717  1.235074  4.735878  1.678928 -1.881256  0.291053  1.781230  1.398565  3.934110  ... -1.572505 -1.981386 -1.908951  3.034426 -4.374824  0.489178 -3.051432 -2.832758 -2.986957 -1.558040  4.542650 -0.078699  2.846123  2.866818 -2.151008  0.465624  3.206414 -2.886617 -0.973224  4.858570  0.401090  1.429223 -1.306388  2.436626  0.375304  0.796462 -1.397474  0.019915 -4.959344 -0.943585  0.348210 -2.54955  1.375585 -3.331098  0.260209 -1.60476  4.503458  0.519022  2.495067 -2.482817 -2.561544 -0.005109 -0.008450 -0.523985  1.464158  0.655260 -0.055013  0.743994  2.011905  0.713488\n",
       "67762    1.256375 -0.135355 -0.094411 -2.881465 -2.859680  0.219944 -2.651040 -0.448493 -4.705667 -2.737536 -2.651793 -1.025328  3.507258 -0.903140 -0.954022 -0.176986 -0.129408 -0.903812 -1.485689 -1.232078  1.635235  0.191120  2.317544 -0.78316 -0.922034 -0.601006  1.982776  0.541685 -0.317295  1.846201  0.336760 -1.875458  1.001356 -2.466253  1.808531 -1.687020  1.17516 -2.430258  0.835395  3.409604 -2.234955  1.543343 -0.720782  4.805836 -0.952767 -3.785604  2.363004  0.964829  1.373647 -1.082907  ...  2.292294  0.804790  1.512545 -2.500110 -0.781102 -4.062862 -2.441689  1.630657  1.479393 -2.077727  2.233886 -1.078675  0.713491 -0.945299 -0.759625  0.223324  3.597754 -1.059106  1.967239  3.818967  1.521663 -1.366154  1.490747  1.029143  1.499049 -0.089437 -1.194861  0.879334  0.018344 -0.082374 -3.172344 -2.91691  0.775857  3.820774 -1.552581 -3.47731 -1.286526 -1.216785 -0.149395 -1.064123  1.278076  1.322566 -2.070811 -2.692464 -2.537409 -2.680542  0.139775  2.710567  2.210895 -2.694886\n",
       "\n",
       "[2 rows x 256 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_profile.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id\n",
       "1    [62164, 11558, 81694, 58100, 27620, 44657, 503...\n",
       "2       [53232, 52524, 19348, 22217, 879, 52537, 8197]\n",
       "Name: item_id, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_list.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>phase</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_city_level</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420</td>\n",
       "      <td>26220</td>\n",
       "      <td>0.9837396808253338</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4.158704</td>\n",
       "      <td>-2.213841</td>\n",
       "      <td>3.299623</td>\n",
       "      <td>-3.816672</td>\n",
       "      <td>1.817951</td>\n",
       "      <td>-0.562453</td>\n",
       "      <td>-3.637601</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-5.418423</td>\n",
       "      <td>-2.103671</td>\n",
       "      <td>-0.442526</td>\n",
       "      <td>-3.839618</td>\n",
       "      <td>4.380653</td>\n",
       "      <td>-3.727894</td>\n",
       "      <td>1.042084</td>\n",
       "      <td>-2.424195</td>\n",
       "      <td>3.287570</td>\n",
       "      <td>-0.606853</td>\n",
       "      <td>-1.033391</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>-0.038618</td>\n",
       "      <td>-1.071147</td>\n",
       "      <td>0.780368</td>\n",
       "      <td>-0.15989</td>\n",
       "      <td>-1.548846</td>\n",
       "      <td>-2.328499</td>\n",
       "      <td>-0.205781</td>\n",
       "      <td>-3.355978</td>\n",
       "      <td>-5.415924</td>\n",
       "      <td>-1.503188</td>\n",
       "      <td>-5.305884</td>\n",
       "      <td>-1.843716</td>\n",
       "      <td>-0.245827</td>\n",
       "      <td>3.008088</td>\n",
       "      <td>3.399326</td>\n",
       "      <td>-3.194445</td>\n",
       "      <td>-3.39710</td>\n",
       "      <td>-0.312699</td>\n",
       "      <td>2.398918</td>\n",
       "      <td>4.553303</td>\n",
       "      <td>-2.690272</td>\n",
       "      <td>1.037717</td>\n",
       "      <td>1.235074</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.572505</td>\n",
       "      <td>-1.981386</td>\n",
       "      <td>-1.908951</td>\n",
       "      <td>3.034426</td>\n",
       "      <td>-4.374824</td>\n",
       "      <td>0.489178</td>\n",
       "      <td>-3.051432</td>\n",
       "      <td>-2.832758</td>\n",
       "      <td>-2.986957</td>\n",
       "      <td>-1.558040</td>\n",
       "      <td>4.542650</td>\n",
       "      <td>-0.078699</td>\n",
       "      <td>2.846123</td>\n",
       "      <td>2.866818</td>\n",
       "      <td>-2.151008</td>\n",
       "      <td>0.465624</td>\n",
       "      <td>3.206414</td>\n",
       "      <td>-2.886617</td>\n",
       "      <td>-0.973224</td>\n",
       "      <td>4.858570</td>\n",
       "      <td>0.401090</td>\n",
       "      <td>1.429223</td>\n",
       "      <td>-1.306388</td>\n",
       "      <td>2.436626</td>\n",
       "      <td>0.375304</td>\n",
       "      <td>0.796462</td>\n",
       "      <td>-1.397474</td>\n",
       "      <td>0.019915</td>\n",
       "      <td>-4.959344</td>\n",
       "      <td>-0.943585</td>\n",
       "      <td>0.348210</td>\n",
       "      <td>-2.54955</td>\n",
       "      <td>1.375585</td>\n",
       "      <td>-3.331098</td>\n",
       "      <td>0.260209</td>\n",
       "      <td>-1.60476</td>\n",
       "      <td>4.503458</td>\n",
       "      <td>0.519022</td>\n",
       "      <td>2.495067</td>\n",
       "      <td>-2.482817</td>\n",
       "      <td>-2.561544</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.008450</td>\n",
       "      <td>-0.523985</td>\n",
       "      <td>1.464158</td>\n",
       "      <td>0.655260</td>\n",
       "      <td>-0.055013</td>\n",
       "      <td>0.743994</td>\n",
       "      <td>2.011905</td>\n",
       "      <td>0.713488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>420</td>\n",
       "      <td>67762</td>\n",
       "      <td>0.9837398562121692</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.256375</td>\n",
       "      <td>-0.135355</td>\n",
       "      <td>-0.094411</td>\n",
       "      <td>-2.881465</td>\n",
       "      <td>-2.859680</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>-2.651040</td>\n",
       "      <td>-0.448493</td>\n",
       "      <td>-4.705667</td>\n",
       "      <td>-2.737536</td>\n",
       "      <td>-2.651793</td>\n",
       "      <td>-1.025328</td>\n",
       "      <td>3.507258</td>\n",
       "      <td>-0.903140</td>\n",
       "      <td>-0.954022</td>\n",
       "      <td>-0.176986</td>\n",
       "      <td>-0.129408</td>\n",
       "      <td>-0.903812</td>\n",
       "      <td>-1.485689</td>\n",
       "      <td>-1.232078</td>\n",
       "      <td>1.635235</td>\n",
       "      <td>0.191120</td>\n",
       "      <td>2.317544</td>\n",
       "      <td>-0.78316</td>\n",
       "      <td>-0.922034</td>\n",
       "      <td>-0.601006</td>\n",
       "      <td>1.982776</td>\n",
       "      <td>0.541685</td>\n",
       "      <td>-0.317295</td>\n",
       "      <td>1.846201</td>\n",
       "      <td>0.336760</td>\n",
       "      <td>-1.875458</td>\n",
       "      <td>1.001356</td>\n",
       "      <td>-2.466253</td>\n",
       "      <td>1.808531</td>\n",
       "      <td>-1.687020</td>\n",
       "      <td>1.17516</td>\n",
       "      <td>-2.430258</td>\n",
       "      <td>0.835395</td>\n",
       "      <td>3.409604</td>\n",
       "      <td>-2.234955</td>\n",
       "      <td>1.543343</td>\n",
       "      <td>-0.720782</td>\n",
       "      <td>...</td>\n",
       "      <td>2.292294</td>\n",
       "      <td>0.804790</td>\n",
       "      <td>1.512545</td>\n",
       "      <td>-2.500110</td>\n",
       "      <td>-0.781102</td>\n",
       "      <td>-4.062862</td>\n",
       "      <td>-2.441689</td>\n",
       "      <td>1.630657</td>\n",
       "      <td>1.479393</td>\n",
       "      <td>-2.077727</td>\n",
       "      <td>2.233886</td>\n",
       "      <td>-1.078675</td>\n",
       "      <td>0.713491</td>\n",
       "      <td>-0.945299</td>\n",
       "      <td>-0.759625</td>\n",
       "      <td>0.223324</td>\n",
       "      <td>3.597754</td>\n",
       "      <td>-1.059106</td>\n",
       "      <td>1.967239</td>\n",
       "      <td>3.818967</td>\n",
       "      <td>1.521663</td>\n",
       "      <td>-1.366154</td>\n",
       "      <td>1.490747</td>\n",
       "      <td>1.029143</td>\n",
       "      <td>1.499049</td>\n",
       "      <td>-0.089437</td>\n",
       "      <td>-1.194861</td>\n",
       "      <td>0.879334</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>-0.082374</td>\n",
       "      <td>-3.172344</td>\n",
       "      <td>-2.91691</td>\n",
       "      <td>0.775857</td>\n",
       "      <td>3.820774</td>\n",
       "      <td>-1.552581</td>\n",
       "      <td>-3.47731</td>\n",
       "      <td>-1.286526</td>\n",
       "      <td>-1.216785</td>\n",
       "      <td>-0.149395</td>\n",
       "      <td>-1.064123</td>\n",
       "      <td>1.278076</td>\n",
       "      <td>1.322566</td>\n",
       "      <td>-2.070811</td>\n",
       "      <td>-2.692464</td>\n",
       "      <td>-2.537409</td>\n",
       "      <td>-2.680542</td>\n",
       "      <td>0.139775</td>\n",
       "      <td>2.710567</td>\n",
       "      <td>2.210895</td>\n",
       "      <td>-2.694886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 263 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id                time  phase  user_age_level  user_gender  user_city_level         0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22       23        24        25        26        27        28        29        30        31        32        33        34        35       36        37        38        39        40        41        42  ...       206       207       208       209       210       211       212       213       214       215       216       217       218       219       220       221       222       223       224       225       226       227       228       229       230       231       232       233       234       235       236      237       238       239       240      241       242       243       244       245       246       247       248       249       250       251       252       253       254       255\n",
       "0      420    26220  0.9837396808253338      0               8            2                5  4.158704 -2.213841  3.299623 -3.816672  1.817951 -0.562453 -3.637601 -0.311089 -5.418423 -2.103671 -0.442526 -3.839618  4.380653 -3.727894  1.042084 -2.424195  3.287570 -0.606853 -1.033391  0.160277 -0.038618 -1.071147  0.780368 -0.15989 -1.548846 -2.328499 -0.205781 -3.355978 -5.415924 -1.503188 -5.305884 -1.843716 -0.245827  3.008088  3.399326 -3.194445 -3.39710 -0.312699  2.398918  4.553303 -2.690272  1.037717  1.235074  ... -1.572505 -1.981386 -1.908951  3.034426 -4.374824  0.489178 -3.051432 -2.832758 -2.986957 -1.558040  4.542650 -0.078699  2.846123  2.866818 -2.151008  0.465624  3.206414 -2.886617 -0.973224  4.858570  0.401090  1.429223 -1.306388  2.436626  0.375304  0.796462 -1.397474  0.019915 -4.959344 -0.943585  0.348210 -2.54955  1.375585 -3.331098  0.260209 -1.60476  4.503458  0.519022  2.495067 -2.482817 -2.561544 -0.005109 -0.008450 -0.523985  1.464158  0.655260 -0.055013  0.743994  2.011905  0.713488\n",
       "1      420    67762  0.9837398562121692      0               8            2                5  1.256375 -0.135355 -0.094411 -2.881465 -2.859680  0.219944 -2.651040 -0.448493 -4.705667 -2.737536 -2.651793 -1.025328  3.507258 -0.903140 -0.954022 -0.176986 -0.129408 -0.903812 -1.485689 -1.232078  1.635235  0.191120  2.317544 -0.78316 -0.922034 -0.601006  1.982776  0.541685 -0.317295  1.846201  0.336760 -1.875458  1.001356 -2.466253  1.808531 -1.687020  1.17516 -2.430258  0.835395  3.409604 -2.234955  1.543343 -0.720782  ...  2.292294  0.804790  1.512545 -2.500110 -0.781102 -4.062862 -2.441689  1.630657  1.479393 -2.077727  2.233886 -1.078675  0.713491 -0.945299 -0.759625  0.223324  3.597754 -1.059106  1.967239  3.818967  1.521663 -1.366154  1.490747  1.029143  1.499049 -0.089437 -1.194861  0.879334  0.018344 -0.082374 -3.172344 -2.91691  0.775857  3.820774 -1.552581 -3.47731 -1.286526 -1.216785 -0.149395 -1.064123  1.278076  1.322566 -2.070811 -2.692464 -2.537409 -2.680542  0.139775  2.710567  2.210895 -2.694886\n",
       "\n",
       "[2 rows x 263 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6066/6066 [00:41<00:00, 144.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = gen_data_set(data, negsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(857,\n",
       "  [45663, 7999, 43277, 45464, 41444, 25060, 59320],\n",
       "  4319,\n",
       "  1,\n",
       "  7,\n",
       "  [1.0528055429458618,\n",
       "   1.128563642501831,\n",
       "   -0.19476017355918884,\n",
       "   -2.8232998847961426,\n",
       "   -1.0138307809829712,\n",
       "   -0.17025381326675415,\n",
       "   -1.7379908561706543,\n",
       "   2.036206722259521,\n",
       "   -4.2752180099487305,\n",
       "   -2.896310567855835,\n",
       "   2.8508329391479488,\n",
       "   -1.0319020748138428,\n",
       "   4.0007572174072275,\n",
       "   0.5457701086997986,\n",
       "   -1.5669609308242798,\n",
       "   1.7627053260803225,\n",
       "   -0.7388931512832642,\n",
       "   -0.9483394026756288,\n",
       "   -0.21662521362304688,\n",
       "   -0.5011007189750671,\n",
       "   -2.277186870574951,\n",
       "   -2.8989429473876958,\n",
       "   0.402845561504364,\n",
       "   -0.3285502791404724,\n",
       "   0.6879732608795166,\n",
       "   -0.11109140515327454,\n",
       "   4.7324934005737305,\n",
       "   -1.882719039916992,\n",
       "   -1.33441424369812,\n",
       "   3.06593656539917,\n",
       "   -2.705151319503784,\n",
       "   -2.0082178115844727,\n",
       "   -3.4601364135742188,\n",
       "   -0.5322337150573729,\n",
       "   2.6357357501983643,\n",
       "   2.2899339199066158,\n",
       "   -3.3446762561798096,\n",
       "   -3.060894012451172,\n",
       "   2.4056987762451167,\n",
       "   2.398726463317871,\n",
       "   -0.29768607020378113,\n",
       "   -2.1010007858276367,\n",
       "   -0.32981958985328674,\n",
       "   3.1818385124206543,\n",
       "   1.811474323272705,\n",
       "   -6.27901554107666,\n",
       "   -2.3466598987579346,\n",
       "   -1.942488431930542,\n",
       "   2.335160493850708,\n",
       "   1.1303038597106934,\n",
       "   1.287590742111206,\n",
       "   1.3782066106796265,\n",
       "   2.7767035961151123,\n",
       "   -5.326404094696045,\n",
       "   2.2920870780944824,\n",
       "   0.8701790571212769,\n",
       "   -0.6613297462463379,\n",
       "   -3.908621072769165,\n",
       "   2.0312626361846924,\n",
       "   2.1952466964721684,\n",
       "   3.007675647735596,\n",
       "   -3.3967976570129395,\n",
       "   0.5771945118904114,\n",
       "   -2.443789482116699,\n",
       "   2.3431167602539062,\n",
       "   -0.8942659497261047,\n",
       "   -2.7316393852233887,\n",
       "   -2.5584211349487305,\n",
       "   -1.9661948680877688,\n",
       "   -1.0520247220993042,\n",
       "   0.2463941127061844,\n",
       "   0.329668402671814,\n",
       "   -1.729242920875549,\n",
       "   0.6933884024620056,\n",
       "   -3.471867561340332,\n",
       "   4.475973129272461,\n",
       "   0.6251246929168701,\n",
       "   2.044265985488892,\n",
       "   -3.0857186317443848,\n",
       "   -0.8036170005798341,\n",
       "   -2.4291341304779053,\n",
       "   3.209519863128662,\n",
       "   3.0745420455932617,\n",
       "   3.808600425720215,\n",
       "   0.05082695186138153,\n",
       "   -0.1298455446958542,\n",
       "   -0.057431861758232124,\n",
       "   -0.8774441480636597,\n",
       "   -2.560988664627075,\n",
       "   -1.4688591957092283,\n",
       "   -1.546494722366333,\n",
       "   0.3940856754779816,\n",
       "   -1.4184348583221436,\n",
       "   -1.1565797328948977,\n",
       "   3.697989463806152,\n",
       "   -1.5236198902130127,\n",
       "   -0.4909436106681824,\n",
       "   2.386603116989136,\n",
       "   -0.967444121837616,\n",
       "   -0.3258779644966125,\n",
       "   -0.2723553776741028,\n",
       "   -5.120533466339111,\n",
       "   0.693217396736145,\n",
       "   0.2300221771001816,\n",
       "   -0.654538631439209,\n",
       "   0.12427639961242674,\n",
       "   1.8243463039398196,\n",
       "   0.2208212614059448,\n",
       "   -4.910792350769043,\n",
       "   2.2342100143432617,\n",
       "   3.0123615264892583,\n",
       "   0.17788781225681305,\n",
       "   0.2342463731765747,\n",
       "   1.0055099725723269,\n",
       "   0.6785930395126343,\n",
       "   2.901771783828736,\n",
       "   -2.9462964534759517,\n",
       "   -0.06738018989562987,\n",
       "   -2.821962833404541,\n",
       "   5.2754249572753915,\n",
       "   -0.27146705985069275,\n",
       "   -0.4510510563850403,\n",
       "   -1.2023621797561646,\n",
       "   1.7663301229476929,\n",
       "   -4.086475372314453,\n",
       "   -5.306974411010742,\n",
       "   4.721138954162598,\n",
       "   1.0504190921783447,\n",
       "   -2.70911717414856,\n",
       "   -1.82397985458374,\n",
       "   -3.413121461868286,\n",
       "   -2.1155233383178706,\n",
       "   0.07404917478561401,\n",
       "   2.0420870780944824,\n",
       "   0.3540906310081482,\n",
       "   0.6798514723777771,\n",
       "   1.6040260791778564,\n",
       "   -3.1622307300567627,\n",
       "   -4.086607933044434,\n",
       "   -2.04872465133667,\n",
       "   -1.1168034076690674,\n",
       "   -0.4578297436237335,\n",
       "   1.2386120557785034,\n",
       "   -1.4336858987808228,\n",
       "   -0.17978912591934204,\n",
       "   1.7941756248474119,\n",
       "   0.6709136366844177,\n",
       "   -0.1104247123003006,\n",
       "   1.1561998128890991,\n",
       "   4.568045616149902,\n",
       "   -0.8612425923347473,\n",
       "   2.0545897483825684,\n",
       "   -0.2999672889709473,\n",
       "   1.014352321624756,\n",
       "   -3.98725175857544,\n",
       "   1.0825428962707522,\n",
       "   -1.8366246223449707,\n",
       "   3.657995223999024,\n",
       "   2.530125617980957,\n",
       "   0.41990575194358826,\n",
       "   -4.329788684844972,\n",
       "   -2.7265281677246094,\n",
       "   2.0906422138214107,\n",
       "   3.1655576229095463,\n",
       "   -1.9887501001358032,\n",
       "   0.4187767803668976,\n",
       "   2.1395275592803955,\n",
       "   0.7792578339576721,\n",
       "   -1.7814184427261353,\n",
       "   -2.2205650806427,\n",
       "   2.7723398208618164,\n",
       "   0.4104539155960083,\n",
       "   1.0576322078704834,\n",
       "   2.136040449142456,\n",
       "   3.742375612258911,\n",
       "   1.6800329685211182,\n",
       "   -0.8262282013893127,\n",
       "   -1.1740972995758057,\n",
       "   0.4813072979450226,\n",
       "   1.6710721254348757,\n",
       "   -5.280901908874512,\n",
       "   -2.750122308731079,\n",
       "   0.1229233741760254,\n",
       "   4.637304306030273,\n",
       "   0.557194709777832,\n",
       "   -2.16260290145874,\n",
       "   2.7780933380126958,\n",
       "   2.2153682708740234,\n",
       "   3.0672733783721924,\n",
       "   -2.9212050437927246,\n",
       "   0.959500014781952,\n",
       "   1.0849230289459229,\n",
       "   0.07438282668590546,\n",
       "   -0.2404126822948456,\n",
       "   3.2144694328308105,\n",
       "   -1.1757173538208008,\n",
       "   3.668301105499268,\n",
       "   3.644885540008545,\n",
       "   -2.5388762950897217,\n",
       "   -1.6003661155700684,\n",
       "   -3.4158637523651123,\n",
       "   -1.8141640424728396,\n",
       "   -1.9069207906723025,\n",
       "   1.8067116737365725,\n",
       "   0.08395147323608397,\n",
       "   -0.8476052284240723,\n",
       "   0.07650480419397354,\n",
       "   1.875756025314331,\n",
       "   -3.8403437137603764,\n",
       "   -1.1387306451797483,\n",
       "   2.28565001487732,\n",
       "   -1.9194483757019043,\n",
       "   -1.8411207199096682,\n",
       "   -0.3285154700279236,\n",
       "   -0.30381640791893005,\n",
       "   0.013148009777069092,\n",
       "   1.8437757492065432,\n",
       "   -1.6335799694061282,\n",
       "   0.5305841565132141,\n",
       "   0.8669008612632751,\n",
       "   3.187584400177002,\n",
       "   -2.615198373794556,\n",
       "   1.6942936182022097,\n",
       "   -0.9146093130111694,\n",
       "   1.4604547023773191,\n",
       "   2.6206536293029785,\n",
       "   -2.204228401184082,\n",
       "   1.0566189289093018,\n",
       "   0.3864514827728272,\n",
       "   3.3139920234680176,\n",
       "   -0.2695096135139465,\n",
       "   1.3759605884552002,\n",
       "   -0.8733929991722107,\n",
       "   -3.1448962688446045,\n",
       "   1.421227216720581,\n",
       "   1.1294088363647459,\n",
       "   -1.2501139640808103,\n",
       "   -1.012934327125549,\n",
       "   -1.5986871719360352,\n",
       "   -0.0731058418750763,\n",
       "   -1.3003344535827637,\n",
       "   -1.0708872079849243,\n",
       "   -0.39969539642333984,\n",
       "   -4.410193920135498,\n",
       "   -3.162602424621582,\n",
       "   -0.7218531370162964,\n",
       "   -1.2597908973693848,\n",
       "   -2.524197816848755,\n",
       "   2.684137344360352,\n",
       "   -1.3556249141693115,\n",
       "   -1.5360465049743652,\n",
       "   0.9914379119873048,\n",
       "   2.9585695266723637,\n",
       "   2.879575252532959,\n",
       "   2.566279649734497,\n",
       "   -1.5135226249694824])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [line[1] for line in train_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[45663, 7999, 43277, 45464, 41444, 25060, 59320],\n",
       " [19719,\n",
       "  27928,\n",
       "  63186,\n",
       "  63827,\n",
       "  80452,\n",
       "  6408,\n",
       "  54281,\n",
       "  45307,\n",
       "  17653,\n",
       "  24196,\n",
       "  61131,\n",
       "  72958,\n",
       "  9440,\n",
       "  72479,\n",
       "  36751,\n",
       "  51318,\n",
       "  30367,\n",
       "  3717,\n",
       "  74443,\n",
       "  61311,\n",
       "  71410,\n",
       "  23083,\n",
       "  65564,\n",
       "  71187,\n",
       "  52030,\n",
       "  16487,\n",
       "  51340,\n",
       "  45683,\n",
       "  60834,\n",
       "  24248,\n",
       "  17653,\n",
       "  39669,\n",
       "  73232,\n",
       "  66208,\n",
       "  52686]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_input, train_label = gen_model_input(train_set, user_profile, SEQ_LEN)\n",
    "test_model_input, test_label = gen_model_input(test_set, user_profile, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': array([5381, 4019, 3664, ..., 1329, 2998, 3026]),\n",
       " 'item_id': array([15386, 46739, 44077, ...,   923,  3669, 62612]),\n",
       " 'hist_item_id': array([[27661, 20909, 23085, ...,     0,     0,     0],\n",
       "        [ 3111, 47064,  3350, ..., 81596, 49674,  7942],\n",
       "        [20794, 48904, 73892, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [54768, 36653,  3127, ...,     0,     0,     0],\n",
       "        [39183, 76659, 56312, ..., 27590, 56160, 31816],\n",
       "        [  701, 76651,  3024, ...,     0,     0,     0]], dtype=int32),\n",
       " 'hist_len': array([40, 58, 12, ..., 16, 57, 18]),\n",
       " 'item_feat_last': array([[-1.60878205, -0.08759964, -0.43949628, ..., -0.1404233 ,\n",
       "          1.99800789, -2.74842024],\n",
       "        [ 2.21175838, -4.83768463,  3.36969185, ...,  3.06375003,\n",
       "          2.31905413, -0.42470151],\n",
       "        [ 2.96954632,  1.35837245,  3.38686228, ...,  1.49628675,\n",
       "         -1.77107739, -1.30099368],\n",
       "        ...,\n",
       "        [ 1.78895044,  1.15014434,  1.34286404, ...,  2.1780057 ,\n",
       "          1.22753143,  2.7657361 ],\n",
       "        [ 0.07365582,  1.1524843 ,  0.31667316, ...,  1.7762382 ,\n",
       "          1.11753321, -0.24067932],\n",
       "        [ 0.90269923, -2.9382205 , -0.38338768, ...,  2.71656561,\n",
       "          1.70225406, -0.69874108]]),\n",
       " 'user_gender': array([2, 2, 2, ..., 2, 2, 3]),\n",
       " 'user_age_level': array([5, 9, 3, ..., 5, 8, 4]),\n",
       " 'user_city_level': array([6, 7, 5, ..., 2, 4, 3])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "\n",
    "user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], 16),\n",
    "                        SparseFeat(\"user_gender\", feature_max_idx['user_gender'], 16),\n",
    "                        SparseFeat(\"user_age_level\", feature_max_idx['user_age_level'], 16),\n",
    "                        SparseFeat(\"user_city_level\", feature_max_idx['user_city_level'], 16),\n",
    "                        VarLenSparseFeat(SparseFeat('hist_item_id', feature_max_idx['item_id'], embedding_dim,\n",
    "                                                    embedding_name=\"item_id\"), SEQ_LEN, 'mean', 'hist_len'),\n",
    "                        ]\n",
    "\n",
    "item_feature_columns = [SparseFeat('item_id', feature_max_idx['item_id'], embedding_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method SequencePoolingLayer.call of <deepctr.layers.sequence.SequencePoolingLayer object at 0x144b039d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SequencePoolingLayer.call of <deepctr.layers.sequence.SequencePoolingLayer object at 0x144b039d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method SequencePoolingLayer.call of <deepctr.layers.sequence.SequencePoolingLayer object at 0x144b039d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SequencePoolingLayer.call of <deepctr.layers.sequence.SequencePoolingLayer object at 0x144b039d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/deepctr/layers/utils.py:167: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/deepctr/layers/utils.py:193: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144acd050>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /Users/luoyonggui/anaconda3/envs/tf14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1288: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method DNN.call of <deepctr.layers.core.DNN object at 0x144a98c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DNN.call of <deepctr.layers.core.DNN object at 0x144a98c50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method DNN.call of <deepctr.layers.core.DNN object at 0x144a98c50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method DNN.call of <deepctr.layers.core.DNN object at 0x144a98c50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x144a92650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x144a92650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x144a92650>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method EmbeddingIndex.call of <deepmatch.layers.core.EmbeddingIndex object at 0x144a92650>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144a8db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144a8db10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144a8db10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method NoMask.call of <deepctr.layers.utils.NoMask object at 0x144a8db10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x144a0d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x144a0d590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x144a0d590>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method PoolingLayer.call of <deepmatch.layers.core.PoolingLayer object at 0x144a0d590>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x144a90610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x144a90610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x144a90610>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method SampledSoftmaxLayer.call of <deepmatch.layers.core.SampledSoftmaxLayer object at 0x144a90610>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "# 3.Define Model and train\n",
    "\n",
    "K.set_learning_phase(True)\n",
    "\n",
    "model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=200, user_dnn_hidden_units=(128,64, embedding_dim))\n",
    "# model = MIND(user_feature_columns,item_feature_columns,dynamic_k=True,p=1,k_max=2,num_sampled=5,user_dnn_hidden_units=(64,16),init_std=0.001)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=sampledsoftmaxloss)  # \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "243030/243030 [==============================] - 31s 126us/sample - loss: 3.8907\n",
      "Epoch 2/24\n",
      "243030/243030 [==============================] - 29s 120us/sample - loss: 3.8230\n",
      "Epoch 3/24\n",
      "243030/243030 [==============================] - 29s 118us/sample - loss: 3.7958\n",
      "Epoch 4/24\n",
      "243030/243030 [==============================] - 28s 117us/sample - loss: 3.7104\n",
      "Epoch 5/24\n",
      "243030/243030 [==============================] - 28s 117us/sample - loss: 3.6789\n",
      "Epoch 6/24\n",
      "243030/243030 [==============================] - 29s 118us/sample - loss: 3.6488\n",
      "Epoch 7/24\n",
      "243030/243030 [==============================] - 29s 118us/sample - loss: 3.5647\n",
      "Epoch 8/24\n",
      "243030/243030 [==============================] - 29s 120us/sample - loss: 3.5314\n",
      "Epoch 9/24\n",
      "243030/243030 [==============================] - 30s 122us/sample - loss: 3.5030\n",
      "Epoch 10/24\n",
      "243030/243030 [==============================] - 30s 122us/sample - loss: 3.4246\n",
      "Epoch 11/24\n",
      "243030/243030 [==============================] - 30s 122us/sample - loss: 3.3949\n",
      "Epoch 12/24\n",
      "243030/243030 [==============================] - 32s 133us/sample - loss: 3.3147\n",
      "Epoch 13/24\n",
      "243030/243030 [==============================] - 29s 121us/sample - loss: 3.2624\n",
      "Epoch 14/24\n",
      "243030/243030 [==============================] - 29s 121us/sample - loss: 3.1910\n",
      "Epoch 15/24\n",
      "243030/243030 [==============================] - 30s 125us/sample - loss: 3.1229\n",
      "Epoch 16/24\n",
      "243030/243030 [==============================] - 29s 121us/sample - loss: 3.0591\n",
      "Epoch 17/24\n",
      "243030/243030 [==============================] - 29s 119us/sample - loss: 2.9884\n",
      "Epoch 18/24\n",
      "243030/243030 [==============================] - 29s 118us/sample - loss: 2.9225\n",
      "Epoch 19/24\n",
      "243030/243030 [==============================] - 31s 128us/sample - loss: 2.8541\n",
      "Epoch 20/24\n",
      "243030/243030 [==============================] - 29s 118us/sample - loss: 2.8166\n",
      "Epoch 21/24\n",
      "243030/243030 [==============================] - 29s 119us/sample - loss: 2.7446\n",
      "Epoch 22/24\n",
      "243030/243030 [==============================] - 28s 115us/sample - loss: 2.6791\n",
      "Epoch 23/24\n",
      "243030/243030 [==============================] - 29s 121us/sample - loss: 2.6290\n",
      "Epoch 24/24\n",
      "243030/243030 [==============================] - 32s 131us/sample - loss: 2.5286\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_label,  # train_label,\n",
    "                    batch_size=512, epochs=24, verbose=1, validation_split=0.0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6066, 32)\n",
      "(82120, 32)\n"
     ]
    }
   ],
   "source": [
    "test_user_model_input = test_model_input\n",
    "# all_item_model_input = {\"item_id\": item_profile['item_id'].values,}\n",
    "all_item_model_input = {\"item_id\": np.array(list(item_profile.index)),}\n",
    "\n",
    "# 以下两行是deepmatch中的通用使用方法，分别获得用户向量模型和物品向量模型\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "# 输入对应的数据拿到对应的向量\n",
    "user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "# user_embs = user_embs[:, i, :]  i in [0,k_max) if MIND\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6066,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_model_input['user_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6066it [01:06, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "recall 0.01071546323771843\n",
      "hit rate 0.01071546323771843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_true_label = {line[0]:[line[2]] for line in test_set}  # user_id: [next_item_id]\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from deepmatch.utils import recall_N\n",
    "\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "# faiss.normalize_L2(item_embs)\n",
    "index.add(item_embs)\n",
    "# faiss.normalize_L2(user_embs)\n",
    "D, I = index.search(user_embs, 50)\n",
    "s = []\n",
    "hit = 0\n",
    "for i, uid in tqdm(enumerate(test_user_model_input['user_id'])):\n",
    "#     try:\n",
    "    tt = np.array(list(item_profile.index))\n",
    "    if True:\n",
    "#         pred = [item_profile['item_id'].values[x] for x in I[i]]\n",
    "        pred = [tt[x] for x in I[i]]\n",
    "        filter_item = None\n",
    "        recall_score = recall_N(test_true_label[uid], pred, N=50)\n",
    "        s.append(recall_score)\n",
    "        if test_true_label[uid] in pred:\n",
    "            hit += 1\n",
    "#     except:\n",
    "# #         print(i)\n",
    "#         pass\n",
    "print(\"\")\n",
    "print(\"recall\", np.mean(s))\n",
    "print(\"hit rate\", hit / len(test_user_model_input['user_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
