{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp algo.ml.tree.lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM, Light Gradient Boosting Machine\n",
    "\n",
    "https://github.com/microsoft/LightGBM\n",
    "\n",
    "LightGBM是使用基于树的学习算法的梯度增强框架。 它被设计为分布式且高效的，具有以下优点：\n",
    "\n",
    "     训练速度更快，效率更高。\n",
    "\n",
    "     降低内存使用率。\n",
    "\n",
    "     更好的准确性。\n",
    "\n",
    "     支持并行和GPU学习。\n",
    "\n",
    "     能够处理大规模数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm==2.2.3\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm -U\n",
    "!pip freeze | grep lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python guide\n",
    "https://github.com/microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple_example\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "\n",
    "\n",
    "    Construct Dataset\n",
    "    Basic train and predict\n",
    "    Eval during training\n",
    "    Early stopping\n",
    "    Save model to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyonggui/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:47: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/lgb_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "# load or create your dataset\n",
    "df_train = pd.read_csv(data_dir + 'regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv(data_dir + 'regression.test', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.243898\tvalid_0's l1: 0.492841\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 0.240605\tvalid_0's l1: 0.489327\n",
      "[3]\tvalid_0's l2: 0.236472\tvalid_0's l1: 0.484931\n",
      "[4]\tvalid_0's l2: 0.232586\tvalid_0's l1: 0.480567\n",
      "[5]\tvalid_0's l2: 0.22865\tvalid_0's l1: 0.475965\n",
      "[6]\tvalid_0's l2: 0.226187\tvalid_0's l1: 0.472861\n",
      "[7]\tvalid_0's l2: 0.223738\tvalid_0's l1: 0.469847\n",
      "[8]\tvalid_0's l2: 0.221012\tvalid_0's l1: 0.466258\n",
      "[9]\tvalid_0's l2: 0.218429\tvalid_0's l1: 0.462751\n",
      "[10]\tvalid_0's l2: 0.215505\tvalid_0's l1: 0.458755\n",
      "[11]\tvalid_0's l2: 0.213027\tvalid_0's l1: 0.455252\n",
      "[12]\tvalid_0's l2: 0.210809\tvalid_0's l1: 0.452051\n",
      "[13]\tvalid_0's l2: 0.208612\tvalid_0's l1: 0.448764\n",
      "[14]\tvalid_0's l2: 0.207468\tvalid_0's l1: 0.446667\n",
      "[15]\tvalid_0's l2: 0.206009\tvalid_0's l1: 0.444211\n",
      "[16]\tvalid_0's l2: 0.20465\tvalid_0's l1: 0.44186\n",
      "[17]\tvalid_0's l2: 0.202489\tvalid_0's l1: 0.438508\n",
      "[18]\tvalid_0's l2: 0.200668\tvalid_0's l1: 0.435919\n",
      "[19]\tvalid_0's l2: 0.19925\tvalid_0's l1: 0.433348\n",
      "[20]\tvalid_0's l2: 0.198136\tvalid_0's l1: 0.431211\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.198136\tvalid_0's l1: 0.431211\n",
      "Saving model...\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 0.44512434910807497\n"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn_example\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/sklearn_example.py\n",
    "\n",
    "\n",
    "    Create data for learning with sklearn interface\n",
    "    Basic train and predict with sklearn interface\n",
    "    Feature importances with sklearn interface\n",
    "    Self-defined eval metric with sklearn interface\n",
    "    Find best parameters for the model with sklearn's GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/lgb_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "# load or create your dataset\n",
    "df_train = pd.read_csv(data_dir + 'regression.train', header=None, sep='\\t')\n",
    "df_test = pd.read_csv(data_dir + 'regression.test', header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.327</td>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>3.102</td>\n",
       "      <td>1.354</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.359</td>\n",
       "      <td>1.498</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.096</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>-1.588</td>\n",
       "      <td>2.173</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.139</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0   1  0.869 -0.635  0.226  0.327 -0.690  0.754 -0.249 -1.092  0.000  ...   \n",
       "1   1  0.908  0.329  0.359  1.498 -0.313  1.096 -0.558 -1.588  2.173  ...   \n",
       "\n",
       "      19     20     21     22     23     24     25     26     27     28  \n",
       "0 -0.010 -0.046  3.102  1.354  0.980  0.978  0.920  0.722  0.989  0.877  \n",
       "1 -1.139 -0.001  0.000  0.302  0.833  0.986  0.978  0.780  0.992  0.798  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.854</td>\n",
       "      <td>-1.126</td>\n",
       "      <td>-0.790</td>\n",
       "      <td>2.173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.744</td>\n",
       "      <td>3.102</td>\n",
       "      <td>0.958</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.385</td>\n",
       "      <td>1.800</td>\n",
       "      <td>1.037</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.349</td>\n",
       "      <td>1.502</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>1.734</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.638</td>\n",
       "      <td>3.102</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.813</td>\n",
       "      <td>1.149</td>\n",
       "      <td>1.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0   1  0.644  0.247 -0.447  0.862  0.374  0.854 -1.126 -0.790  2.173  ...   \n",
       "1   0  0.385  1.800  1.037  1.044  0.349  1.502 -0.966  1.734  0.000  ...   \n",
       "\n",
       "     19     20     21     22     23     24     25     26     27     28  \n",
       "0 -0.19 -0.744  3.102  0.958  1.061  0.980  0.875  0.581  0.905  0.796  \n",
       "1 -0.44  0.638  3.102  0.695  0.909  0.981  0.803  0.813  1.149  1.116  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train[0]\n",
    "y_test = df_test[0]\n",
    "X_train = df_train.drop(0, axis=1)\n",
    "X_test = df_test.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[1]\tvalid_0's l2: 0.242763\tvalid_0's l1: 0.491735\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 0.237895\tvalid_0's l1: 0.486563\n",
      "[3]\tvalid_0's l2: 0.233277\tvalid_0's l1: 0.481489\n",
      "[4]\tvalid_0's l2: 0.22925\tvalid_0's l1: 0.476848\n",
      "[5]\tvalid_0's l2: 0.226155\tvalid_0's l1: 0.47305\n",
      "[6]\tvalid_0's l2: 0.222963\tvalid_0's l1: 0.469049\n",
      "[7]\tvalid_0's l2: 0.220364\tvalid_0's l1: 0.465556\n",
      "[8]\tvalid_0's l2: 0.217872\tvalid_0's l1: 0.462208\n",
      "[9]\tvalid_0's l2: 0.215328\tvalid_0's l1: 0.458676\n",
      "[10]\tvalid_0's l2: 0.212743\tvalid_0's l1: 0.454998\n",
      "[11]\tvalid_0's l2: 0.210805\tvalid_0's l1: 0.452047\n",
      "[12]\tvalid_0's l2: 0.208945\tvalid_0's l1: 0.449158\n",
      "[13]\tvalid_0's l2: 0.206986\tvalid_0's l1: 0.44608\n",
      "[14]\tvalid_0's l2: 0.205513\tvalid_0's l1: 0.443554\n",
      "[15]\tvalid_0's l2: 0.203728\tvalid_0's l1: 0.440643\n",
      "[16]\tvalid_0's l2: 0.201865\tvalid_0's l1: 0.437687\n",
      "[17]\tvalid_0's l2: 0.200639\tvalid_0's l1: 0.435454\n",
      "[18]\tvalid_0's l2: 0.199522\tvalid_0's l1: 0.433288\n",
      "[19]\tvalid_0's l2: 0.198552\tvalid_0's l1: 0.431297\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's l1: 0.428946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's l1: 0.428946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=20, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.LGBMRegressor(num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=20)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.68205502, 0.4812164 , 0.37969294, 0.45091878, 0.38236335])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.4441153344254208\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: [23, 7, 0, 33, 5, 56, 9, 1, 1, 21, 2, 5, 1, 19, 9, 6, 1, 10, 4, 10, 0, 31, 61, 4, 48, 102, 52, 79]\n"
     ]
    }
   ],
   "source": [
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### self-defined eval metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with custom eval function...\n",
      "[1]\tvalid_0's l2: 0.242763\tvalid_0's RMSLE: 0.344957\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 0.237895\tvalid_0's RMSLE: 0.341693\n",
      "[3]\tvalid_0's l2: 0.233277\tvalid_0's RMSLE: 0.338462\n",
      "[4]\tvalid_0's l2: 0.22925\tvalid_0's RMSLE: 0.335656\n",
      "[5]\tvalid_0's l2: 0.226155\tvalid_0's RMSLE: 0.333431\n",
      "[6]\tvalid_0's l2: 0.222963\tvalid_0's RMSLE: 0.331104\n",
      "[7]\tvalid_0's l2: 0.220364\tvalid_0's RMSLE: 0.329193\n",
      "[8]\tvalid_0's l2: 0.217872\tvalid_0's RMSLE: 0.327337\n",
      "[9]\tvalid_0's l2: 0.215328\tvalid_0's RMSLE: 0.325433\n",
      "[10]\tvalid_0's l2: 0.212743\tvalid_0's RMSLE: 0.323523\n",
      "[11]\tvalid_0's l2: 0.210805\tvalid_0's RMSLE: 0.321986\n",
      "[12]\tvalid_0's l2: 0.208945\tvalid_0's RMSLE: 0.320523\n",
      "[13]\tvalid_0's l2: 0.206986\tvalid_0's RMSLE: 0.319027\n",
      "[14]\tvalid_0's l2: 0.205513\tvalid_0's RMSLE: 0.317796\n",
      "[15]\tvalid_0's l2: 0.203728\tvalid_0's RMSLE: 0.316383\n",
      "[16]\tvalid_0's l2: 0.201865\tvalid_0's RMSLE: 0.314827\n",
      "[17]\tvalid_0's l2: 0.200639\tvalid_0's RMSLE: 0.313876\n",
      "[18]\tvalid_0's l2: 0.199522\tvalid_0's RMSLE: 0.312948\n",
      "[19]\tvalid_0's l2: 0.198552\tvalid_0's RMSLE: 0.312116\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's RMSLE: 0.311032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's RMSLE: 0.311032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=20, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self-defined eval metric\n",
    "# f(y_true: array, y_pred: array) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def rmsle(y_true, y_pred):\n",
    "    return 'RMSLE', np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2))), False\n",
    "\n",
    "\n",
    "print('Starting training with custom eval function...')\n",
    "# train\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=rmsle,\n",
    "        early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with multiple custom eval functions...\n",
      "[1]\tvalid_0's l2: 0.242763\tvalid_0's RMSLE: 0.344957\tvalid_0's RAE: 0.991146\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l2: 0.237895\tvalid_0's RMSLE: 0.341693\tvalid_0's RAE: 0.98072\n",
      "[3]\tvalid_0's l2: 0.233277\tvalid_0's RMSLE: 0.338462\tvalid_0's RAE: 0.970493\n",
      "[4]\tvalid_0's l2: 0.22925\tvalid_0's RMSLE: 0.335656\tvalid_0's RAE: 0.961139\n",
      "[5]\tvalid_0's l2: 0.226155\tvalid_0's RMSLE: 0.333431\tvalid_0's RAE: 0.953484\n",
      "[6]\tvalid_0's l2: 0.222963\tvalid_0's RMSLE: 0.331104\tvalid_0's RAE: 0.945419\n",
      "[7]\tvalid_0's l2: 0.220364\tvalid_0's RMSLE: 0.329193\tvalid_0's RAE: 0.938379\n",
      "[8]\tvalid_0's l2: 0.217872\tvalid_0's RMSLE: 0.327337\tvalid_0's RAE: 0.931631\n",
      "[9]\tvalid_0's l2: 0.215328\tvalid_0's RMSLE: 0.325433\tvalid_0's RAE: 0.92451\n",
      "[10]\tvalid_0's l2: 0.212743\tvalid_0's RMSLE: 0.323523\tvalid_0's RAE: 0.917099\n",
      "[11]\tvalid_0's l2: 0.210805\tvalid_0's RMSLE: 0.321986\tvalid_0's RAE: 0.911151\n",
      "[12]\tvalid_0's l2: 0.208945\tvalid_0's RMSLE: 0.320523\tvalid_0's RAE: 0.905328\n",
      "[13]\tvalid_0's l2: 0.206986\tvalid_0's RMSLE: 0.319027\tvalid_0's RAE: 0.899122\n",
      "[14]\tvalid_0's l2: 0.205513\tvalid_0's RMSLE: 0.317796\tvalid_0's RAE: 0.894031\n",
      "[15]\tvalid_0's l2: 0.203728\tvalid_0's RMSLE: 0.316383\tvalid_0's RAE: 0.888164\n",
      "[16]\tvalid_0's l2: 0.201865\tvalid_0's RMSLE: 0.314827\tvalid_0's RAE: 0.882206\n",
      "[17]\tvalid_0's l2: 0.200639\tvalid_0's RMSLE: 0.313876\tvalid_0's RAE: 0.877704\n",
      "[18]\tvalid_0's l2: 0.199522\tvalid_0's RMSLE: 0.312948\tvalid_0's RAE: 0.87334\n",
      "[19]\tvalid_0's l2: 0.198552\tvalid_0's RMSLE: 0.312116\tvalid_0's RAE: 0.869327\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's RMSLE: 0.311032\tvalid_0's RAE: 0.864588\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.197238\tvalid_0's RMSLE: 0.311032\tvalid_0's RAE: 0.864588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=20, n_jobs=-1, num_leaves=31, objective=None,\n",
       "              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another self-defined eval metric\n",
    "# f(y_true: array, y_pred: array) -> name: string, eval_result: float, is_higher_better: bool\n",
    "# Relative Absolute Error (RAE)\n",
    "def rae(y_true, y_pred):\n",
    "    return 'RAE', np.sum(np.abs(y_pred - y_true)) / np.sum(np.abs(np.mean(y_true) - y_true)), False\n",
    "\n",
    "\n",
    "print('Starting training with multiple custom eval functions...')\n",
    "# train\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric=lambda y_true, y_pred: [rmsle(y_true, y_pred), rae(y_true, y_pred)],\n",
    "        early_stopping_rounds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "The rmsle of prediction is: 0.3110323289863278\n",
      "The rae of prediction is: 0.8645881044669875\n"
     ]
    }
   ],
   "source": [
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "# eval\n",
    "print('The rmsle of prediction is:', rmsle(y_test, y_pred)[1])\n",
    "print('The rae of prediction is:', rae(y_test, y_pred)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by grid search are: {'learning_rate': 0.1, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# other scikit-learn modules\n",
    "estimator = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "    'n_estimators': [20, 40]\n",
    "}\n",
    "\n",
    "gbm = GridSearchCV(estimator, param_grid, cv=3)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## advanced_example\n",
    "https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/advanced_example.py\n",
    "\n",
    "\n",
    "    Construct Dataset\n",
    "    Set feature names\n",
    "    Directly use categorical features without one-hot encoding\n",
    "    Save model to file\n",
    "    Dump model to JSON format\n",
    "    Get feature names\n",
    "    Get feature importances\n",
    "    Load model to predict\n",
    "    Dump and load model with pickle\n",
    "    Load model file to continue training\n",
    "    Change learning rates during training\n",
    "    Change any parameters during training\n",
    "    Self-defined objective function\n",
    "    Self-defined eval metric\n",
    "    Callback function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 00_template.ipynb.\n",
      "Converted algo_ml_shallow_tree_catboost.ipynb.\n",
      "Converted dl_keras.ipynb.\n",
      "Converted engineering_nbdev.ipynb.\n",
      "Converted engineering_panel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
