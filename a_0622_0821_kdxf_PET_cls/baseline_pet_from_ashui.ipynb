{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w75C2jQMuugQ"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time, datetime\n",
    "import pdb, traceback\n",
    "\n",
    "import cv2\n",
    "# import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "# model = EfficientNet.from_pretrained('efficientnet-b4') \n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4336,
     "status": "ok",
     "timestamp": 1594552718043,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "o7wWOpq_vTff",
    "outputId": "a046abe0-fbc9-4300-c284-f193b157ab8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train\n"
     ]
    }
   ],
   "source": [
    "!ls drive/'My Drive'/20kdxf_pet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QRDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRDataset(Dataset):\n",
    "    def __init__(self, train_jpg, transform=None):\n",
    "        self.train_jpg = train_jpg\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        start_time = time.time()\n",
    "        img = Image.open(self.train_jpg[index]).convert('RGB')\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img,torch.from_numpy(np.array(int('AD' in self.train_jpg[index])))  # img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisitNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisitNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VisitNet, self).__init__()\n",
    "                \n",
    "        model = models.resnet34(True)\n",
    "        model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        model.fc = nn.Linear(512, 2)\n",
    "        self.resnet = model\n",
    "        \n",
    "    def forward(self, img):        \n",
    "        out = self.resnet(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1255,
     "status": "ok",
     "timestamp": 1594552672739,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "wlC3lZUvvcng"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        \"\"\"\n",
    "        \n",
    "        :fmt: format. 格式\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, *meters):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = \"\"\n",
    "\n",
    "\n",
    "    def pr2int(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    # data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    # top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(len(train_loader), batch_time, losses, top1)\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 2))\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(acc1[0], input.size(0))\n",
    "        # top5.update(acc5[0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            progress.pr2int(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@2', ':6.2f')\n",
    "    progress = ProgressMeter(len(val_loader), batch_time, losses, top1, top5)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 2))\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(acc1[0], input.size(0))\n",
    "            top5.update(acc5[0], input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "        return top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_loader, model, tta=10):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    test_pred_tta = None\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "        with torch.no_grad():\n",
    "            end = time.time()\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "                # compute output\n",
    "                output = model(input, path)\n",
    "                output = output.data.cpu().numpy()\n",
    "\n",
    "                test_pred.append(output)\n",
    "        test_pred = np.vstack(test_pred)\n",
    "    \n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7128,
     "status": "ok",
     "timestamp": 1594552895647,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "TWuVCl_LvtzA"
   },
   "outputs": [],
   "source": [
    "# input dataset\n",
    "train_jpg = np.array(glob.glob(\"drive/My Drive/20kdxf_pet/\"+'train/*/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5934,
     "status": "ok",
     "timestamp": 1594552895649,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "jgmZh31-wgKL",
    "outputId": "d3d562a4-e106-42ce-e016-5fbe79142574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 461677,
     "status": "ok",
     "timestamp": 1594554234507,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "yxyk9lKEwAoR",
    "outputId": "accbbd2f-fc01-4288-8af3-416b8e87e455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0/154]\tTime  2.880 ( 2.880)\tLoss 5.5835e-01 (5.5835e-01)\tAcc@1  90.00 ( 90.00)\n",
      "[100/154]\tTime  0.256 ( 0.286)\tLoss 9.8210e-01 (9.1996e-01)\tAcc@1  60.00 ( 56.14)\n",
      " * Acc@1 56.725 Acc@5 100.000\n",
      "56.72514724731445 0.0\n",
      "save model to drive/My Drive/20kdxf_pet/resnet18_fold0.pt\n",
      "Epoch:  1\n",
      "[  0/154]\tTime  4.278 ( 4.278)\tLoss 4.8046e-01 (4.8046e-01)\tAcc@1  60.00 ( 60.00)\n",
      "[100/154]\tTime  0.253 ( 0.290)\tLoss 1.2288e+00 (6.2199e-01)\tAcc@1  30.00 ( 70.99)\n",
      " * Acc@1 78.947 Acc@5 100.000\n",
      "78.94737243652344 56.72514724731445\n",
      "save model to drive/My Drive/20kdxf_pet/resnet18_fold0.pt\n",
      "Epoch:  2\n",
      "[  0/154]\tTime  2.895 ( 2.895)\tLoss 8.0886e-02 (8.0886e-02)\tAcc@1 100.00 (100.00)\n",
      "[100/154]\tTime  0.251 ( 0.280)\tLoss 4.8473e-01 (4.0343e-01)\tAcc@1  70.00 ( 81.29)\n",
      " * Acc@1 78.947 Acc@5 100.000\n",
      "Epoch:  3\n",
      "[  0/154]\tTime  2.858 ( 2.858)\tLoss 6.6055e-01 (6.6055e-01)\tAcc@1  90.00 ( 90.00)\n",
      "[100/154]\tTime  0.250 ( 0.280)\tLoss 1.7702e-01 (3.2666e-01)\tAcc@1 100.00 ( 87.13)\n",
      " * Acc@1 83.626 Acc@5 100.000\n",
      "83.625732421875 78.94737243652344\n",
      "save model to drive/My Drive/20kdxf_pet/resnet18_fold0.pt\n",
      "Epoch:  4\n",
      "[  0/154]\tTime  3.506 ( 3.506)\tLoss 6.6919e-02 (6.6919e-02)\tAcc@1 100.00 (100.00)\n",
      "[100/154]\tTime  0.249 ( 0.288)\tLoss 3.7493e-01 (3.2294e-01)\tAcc@1  90.00 ( 87.23)\n",
      " * Acc@1 88.889 Acc@5 100.000\n",
      "88.8888931274414 83.625732421875\n",
      "save model to drive/My Drive/20kdxf_pet/resnet18_fold0.pt\n",
      "Epoch:  5\n",
      "[  0/154]\tTime  4.800 ( 4.800)\tLoss 2.4145e-01 (2.4145e-01)\tAcc@1  80.00 ( 80.00)\n",
      "[100/154]\tTime  0.253 ( 0.295)\tLoss 1.7964e-01 (2.7903e-01)\tAcc@1  90.00 ( 90.50)\n",
      " * Acc@1 92.982 Acc@5 100.000\n",
      "92.98246002197266 88.8888931274414\n",
      "save model to drive/My Drive/20kdxf_pet/resnet18_fold0.pt\n",
      "Epoch:  6\n",
      "[  0/154]\tTime  2.864 ( 2.864)\tLoss 3.1593e-01 (3.1593e-01)\tAcc@1  80.00 ( 80.00)\n",
      "[100/154]\tTime  0.252 ( 0.285)\tLoss 7.3865e-02 (2.0170e-01)\tAcc@1 100.00 ( 92.87)\n",
      " * Acc@1 83.626 Acc@5 100.000\n",
      "Epoch:  7\n",
      "[  0/154]\tTime  3.128 ( 3.128)\tLoss 7.7143e-01 (7.7143e-01)\tAcc@1  50.00 ( 50.00)\n",
      "[100/154]\tTime  0.249 ( 0.283)\tLoss 7.9654e-02 (1.7700e-01)\tAcc@1 100.00 ( 92.77)\n",
      " * Acc@1 69.591 Acc@5 100.000\n",
      "Epoch:  8\n",
      "[  0/154]\tTime  4.176 ( 4.176)\tLoss 4.7903e-02 (4.7903e-02)\tAcc@1 100.00 (100.00)\n",
      "[100/154]\tTime  0.252 ( 0.291)\tLoss 1.5541e-01 (1.7361e-01)\tAcc@1  90.00 ( 93.17)\n",
      " * Acc@1 91.228 Acc@5 100.000\n",
      "Epoch:  9\n",
      "[  0/154]\tTime  3.831 ( 3.831)\tLoss 1.9254e-02 (1.9254e-02)\tAcc@1 100.00 (100.00)\n",
      "[100/154]\tTime  0.249 ( 0.287)\tLoss 1.1107e-01 (1.7346e-01)\tAcc@1  90.00 ( 93.56)\n",
      " * Acc@1 91.228 Acc@5 100.000\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=10, random_state=2314, shuffle=True)\n",
    "for flod_idx, (train_idx, val_idx) in enumerate(skf.split(train_jpg, train_jpg)):    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        QRDataset(train_jpg[train_idx],\n",
    "                transforms.Compose([\n",
    "                            # transforms.RandomGrayscale(),\n",
    "                            transforms.Resize((512, 512)),\n",
    "                            transforms.RandomAffine(10),\n",
    "                            # transforms.ColorJitter(hue=.05, saturation=.05),\n",
    "                            # transforms.RandomCrop((450, 450)),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomVerticalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        ), batch_size=10, shuffle=True, num_workers=20, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        QRDataset(train_jpg[val_idx],\n",
    "                transforms.Compose([\n",
    "                            transforms.Resize((512, 512)),\n",
    "                            # transforms.Resize((124, 124)),\n",
    "                            # transforms.RandomCrop((450, 450)),\n",
    "                            # transforms.RandomCrop((88, 88)),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        ), batch_size=10, shuffle=False, num_workers=10, pin_memory=True\n",
    "    )\n",
    "        \n",
    "    \n",
    "    model = VisitNet().cuda()\n",
    "    # model = nn.DataParallel(model).cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 0.01)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.85)\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(10):\n",
    "        scheduler.step()\n",
    "        print('Epoch: ', epoch)\n",
    "\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        val_acc = validate(val_loader, model, criterion)\n",
    "        \n",
    "        if val_acc.avg.item() > best_acc:\n",
    "            print(val_acc.avg.item(), best_acc)\n",
    "            best_acc = val_acc.avg.item()\n",
    "            print(\"save model to drive/My Drive/20kdxf_pet/\"+'resnet18_fold{0}.pt'.format(flod_idx))\n",
    "            torch.save(model.state_dict(), \"drive/My Drive/20kdxf_pet/\"+'resnet18_fold{0}.pt'.format(flod_idx))\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mVzPnGl10F1"
   },
   "source": [
    "# predict f1=0.77989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1594554270330,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "vNz0149awV6O"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os, sys, glob, argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time, datetime\n",
    "import pdb, traceback\n",
    "\n",
    "import cv2\n",
    "# import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "# model = EfficientNet.from_pretrained('efficientnet-b4') \n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1542,
     "status": "ok",
     "timestamp": 1594554367883,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "k9lsyaaI2BSN"
   },
   "outputs": [],
   "source": [
    "test_jpg = [\"drive/My Drive/20kdxf_pet/\"+'test/AD&CN/{0}.png'.format(x) for x in range(1, 1001)]\n",
    "test_jpg = np.array(test_jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 166660,
     "status": "ok",
     "timestamp": 1594554717050,
     "user": {
      "displayName": "ian luo",
      "photoUrl": "",
      "userId": "09210897906652852090"
     },
     "user_tz": -480
    },
    "id": "paiiLSIo2NF0"
   },
   "outputs": [],
   "source": [
    "test_pred = None\n",
    "for model_path in ['resnet18_fold0.pt', 'resnet18_fold1.pt', 'resnet18_fold2.pt',\n",
    "                  'resnet18_fold3.pt', 'resnet18_fold4.pt', 'resnet18_fold5.pt',\n",
    "                  'resnet18_fold6.pt', 'resnet18_fold7.pt', 'resnet18_fold8.pt',\n",
    "                  'resnet18_fold9.pt'][:1]:\n",
    "    \n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        QRDataset(test_jpg,\n",
    "                transforms.Compose([\n",
    "                            transforms.Resize((512, 512)),\n",
    "                            # transforms.CenterCrop((450, 450)),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.RandomVerticalFlip(),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        ), batch_size=10, shuffle=False, num_workers=10, pin_memory=True\n",
    "    )\n",
    "        \n",
    "    \n",
    "    model = VisitNet().cuda()\n",
    "    model.load_state_dict(torch.load(\"drive/My Drive/20kdxf_pet/\"+model_path))\n",
    "    # model = nn.DataParallel(model).cuda()\n",
    "    if test_pred is None:\n",
    "        test_pred = predict(test_loader, model, 5)\n",
    "    else:\n",
    "        test_pred += predict(test_loader, model, 5)\n",
    "    \n",
    "test_csv = pd.DataFrame()\n",
    "test_csv['uuid'] = list(range(1, 1001))\n",
    "test_csv['label'] = np.argmax(test_pred, 1)\n",
    "test_csv['label'] = test_csv['label'].map({1: 'AD', 0: 'CN'})\n",
    "test_csv.to_csv(\"drive/My Drive/20kdxf_pet/\"+'tmp.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQiqzk3B2y6F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMr+4p+wVL8hU0QFu6ZPN1y",
   "mount_file_id": "1ze04tvg1OuOk7lH52PW-WbV8f8jGV21o",
   "name": "baseline_pet_from_ashui.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
